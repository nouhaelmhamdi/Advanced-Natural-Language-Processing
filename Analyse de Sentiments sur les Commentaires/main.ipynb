{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Atelier 1 : Analyse de Sentiments sur les Commentaires YouTube**\n",
                "\n",
                "**Par :** *Nouha EL MHAMDI*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 1 : Importation et Exploration des Données**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **1. Importer les bibliothèques nécessaires**\n",
                "Cette cellule importe toutes les bibliothèques nécessaires pour l'atelier, telles que pandas pour la manipulation des données, et os pour les opérations sur le système de fichiers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
                "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **2. Charger les fichiers CSV**\n",
                "Cette cellule charge les fichiers CSV individuels de commentaires YouTube dans une liste de DataFrames pandas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "files = [r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube01-Psy.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube02-KatyPerry.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube03-LMFAO.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube04-Eminem.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube05-Shakira.csv']\n",
                "dataframes = [pd.read_csv(file) for file in files]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **3. Concaténer les fichiers en un seul corpus**\n",
                "Cette cellule concatène la liste des DataFrames en un seul DataFrame pour créer un corpus unifié de commentaires."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = pd.concat(dataframes, ignore_index=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **4. Afficher un exemple de commentaire et sa classe associée**\n",
                "Cette cellule affiche un exemple de commentaire et sa classe correspondante (1 pour spam, 0 pour non spam) pour avoir une idée des données."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exemple de commentaire :\n",
                        "Huh, anyway check out this you[tube] channel: kobyoshi02\n",
                        "Classe associée : 1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Exemple de commentaire :\")\n",
                "print(data['CONTENT'][0])\n",
                "print(\"Classe associée :\", data['CLASS'][0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-> L'exemple est un cas classique de spam sur YouTube : un commentaire qui n'est pas lié à la vidéo et qui fait la promotion d'une autre chaîne. La classe 1 est donc appropriée."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **5. Vérifier l'équilibrage des classes**\n",
                "Cette cellule vérifie la distribution des deux classes (spam et non spam) pour voir si l'ensemble de données est équilibré. Un ensemble de données déséquilibré peut nécessiter un traitement spécial."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Distribution des classes :\n",
                        "CLASS\n",
                        "1    1005\n",
                        "0     951\n",
                        "Name: count, dtype: int64\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "print(\"Distribution des classes :\")\n",
                "print(data['CLASS'].value_counts())\n",
                "sns.countplot(x='CLASS', data=data)\n",
                "plt.title('Distribution des classes')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** 1005 commentaires de classe 1 (Spam) et 951 de classe 0 (Non-Spam).\n",
                "\n",
                "* **Analyse Logique :** Le graphique et les chiffres montrent que l'ensemble de données est très bien équilibré. Il n'y a pas de déséquilibre majeur entre les commentaires spam et non-spam. C'est une excellente condition de départ, car cela signifie que le modèle ne sera pas naturellement biaisé vers une classe plus fréquente."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 2 : Préparation des Données**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **6. Prétraiter les données**\n",
                "Le prétraitement des données textuelles est crucial. Pour cet atelier, nous allons nous concentrer sur le nettoyage de base : suppression des caractères non-alphanumériques et mise en minuscule. Cela simplifie le vocabulaire et améliore la cohérence des données."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exemple de commentaire nettoyé :\n",
                        "huh anyway check out this youtube channel kobyoshi02\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "\n",
                "# Fonction de nettoyage simple\n",
                "def clean_text(text):\n",
                "    # Remplacer les caractères non-alphanumériques par un espace\n",
                "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', str(text))\n",
                "    # Mettre en minuscule\n",
                "    text = text.lower()\n",
                "    return text\n",
                "\n",
                "# Appliquer le nettoyage à la colonne CONTENT\n",
                "data['CONTENT_CLEANED'] = data['CONTENT'].apply(clean_text)\n",
                "\n",
                "print(\"Exemple de commentaire nettoyé :\")\n",
                "print(data['CONTENT_CLEANED'][0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** huh anyway check out this youtube channel kobyoshi02\n",
                "\n",
                "* **Analyse Logique :** Le texte a été mis en minuscules et les caractères spéciaux (comme [ ] et :) ont été supprimés. C'est une étape de nettoyage standard et essentielle qui simplifie le texte et réduit la taille du vocabulaire, ce qui aide le modèle à mieux apprendre."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **7. Vectoriser les données (pour MLP)**\n",
                "Pour le Perceptron Multicouche (MLP), nous allons utiliser la méthode **Bag-of-Words** via `CountVectorizer`. Cette méthode convertit le texte en une matrice de fréquences de mots, perdant l'ordre séquentiel mais capturant la présence des mots. Nous limitons le vocabulaire aux 5000 mots les plus fréquents pour des raisons de performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Taille du vocabulaire (max_features) : 4252\n",
                        "Forme de la matrice vectorisée : (1956, 4252)\n"
                    ]
                }
            ],
            "source": [
                "X = data['CONTENT_CLEANED']\n",
                "y = data['CLASS']\n",
                "\n",
                "# Initialiser le CountVectorizer\n",
                "vectorizer = CountVectorizer(max_features=5000)\n",
                "\n",
                "# Adapter et transformer les données\n",
                "X_vectorized = vectorizer.fit_transform(X)\n",
                "\n",
                "print(f\"Taille du vocabulaire (max_features) : {len(vectorizer.vocabulary_)}\")\n",
                "print(f\"Forme de la matrice vectorisée : {X_vectorized.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** Matrice de (1956, 4252).\n",
                "\n",
                "* **Analyse Logique :** Les 1956 commentaires ont été transformés en une matrice numérique. Chaque commentaire est maintenant représenté par un vecteur de 4252 chiffres, où chaque chiffre correspond à la fréquence d'un mot du vocabulaire. C'est la représentation Bag-of-Words que le modèle MLP peut comprendre."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **8. Séparer les données en apprentissage et test**\n",
                "Nous séparons l'ensemble de données vectorisé en ensembles d'entraînement et de test pour évaluer la capacité de généralisation du modèle. Un ratio 80/20 est couramment utilisé."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Taille de l'ensemble d'entraînement : 1564 échantillons\n",
                        "Taille de l'ensemble de test : 392 échantillons\n"
                    ]
                }
            ],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Taille de l'ensemble d'entraînement : {X_train.shape[0]} échantillons\")\n",
                "print(f\"Taille de l'ensemble de test : {X_test.shape[0]} échantillons\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** 1564 échantillons pour l'entraînement, 392 pour le test.\n",
                "\n",
                "* **Analyse Logique :** Le jeu de données a été divisé en deux parties (80% pour l'entraînement, 20% pour le test). Le modèle apprendra sur le grand ensemble et sa performance sera validée sur le petit ensemble qu'il n'a jamais vu, ce qui permet de mesurer sa capacité de généralisation."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 3 : Modèle - Perceptron Multicouche (MLP)**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **9. Créer et entraîner le modèle MLP**\n",
                "Le MLP est un réseau de neurones feed-forward qui traite les données vectorisées (Bag-of-Words) comme des caractéristiques indépendantes. Il est simple et efficace pour les tâches de classification de texte où l'ordre des mots n'est pas primordial."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entraînement du modèle MLP...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modèle MLP entraîné.\n"
                    ]
                }
            ],
            "source": [
                "# Convertir les matrices creuses en tableaux denses pour Keras\n",
                "# La méthode .toarray() est utilisée pour convertir la matrice creuse (CSR) en un tableau dense numpy,\n",
                "# ce qui est nécessaire pour l'entrée du modèle MLP dans Keras.\n",
                "X_train_dense = X_train.toarray()\n",
                "X_test_dense = X_test.toarray()\n",
                "\n",
                "# Définir le modèle MLP\n",
                "mlp_model = Sequential([\n",
                "    Dense(128, activation='relu', input_shape=(X_train_dense.shape[1],)),\n",
                "    Dense(64, activation='relu'),\n",
                "    Dense(1, activation='sigmoid')\n",
                "])\n",
                "\n",
                "# Compiler le modèle\n",
                "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "# Entraîner le modèle\n",
                "print(\"Entraînement du modèle MLP...\")\n",
                "mlp_history = mlp_model.fit(X_train_dense, y_train, epochs=5, batch_size=32, verbose=0)\n",
                "\n",
                "print(\"Modèle MLP entraîné.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **10. Évaluer le modèle sur les données d'apprentissage**\n",
                "Une évaluation sur les données d'apprentissage permet de vérifier si le modèle a bien appris le jeu de données (faible biais)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Précision (Accuracy) sur l'ensemble d'apprentissage : 1.0000\n"
                    ]
                }
            ],
            "source": [
                "loss_train, accuracy_train = mlp_model.evaluate(X_train_dense, y_train, verbose=0)\n",
                "print(f\"Précision (Accuracy) sur l'ensemble d'apprentissage : {accuracy_train:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** 1.0000 (100%).\n",
                "\n",
                "* **Analyse Logique :** Le modèle a parfaitement mémorisé l'ensemble des données d'entraînement. C'est un signe clair de surapprentissage (overfitting). Bien que cela montre que le modèle a une capacité d'apprentissage suffisante, sa vraie performance se mesure sur les données de test."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **11. Tester le modèle sur les données de test**\n",
                "L'évaluation sur l'ensemble de test donne une estimation de la performance du modèle sur des données non vues (capacité de généralisation)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Précision (Accuracy) sur l'ensemble de test : 0.8801\n"
                    ]
                }
            ],
            "source": [
                "loss_test, accuracy_test = mlp_model.evaluate(X_test_dense, y_test, verbose=0)\n",
                "print(f\"Précision (Accuracy) sur l'ensemble de test : {accuracy_test:.4f}\")\n",
                "\n",
                "# Stocker la précision pour la comparaison future\n",
                "mlp_accuracy = accuracy_test\n",
                "mlp_loss = loss_test"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **12. Rapport de classification**\n",
                "Le rapport de classification fournit des métriques détaillées (Précision, Rappel, F1-score) pour chaque classe, offrant une vue plus complète de la performance du modèle."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
                        "Rapport de classification pour le MLP :\n",
                        "\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "Non-Spam (0)       0.82      0.94      0.88       176\n",
                        "    Spam (1)       0.94      0.83      0.88       216\n",
                        "\n",
                        "    accuracy                           0.88       392\n",
                        "   macro avg       0.88      0.89      0.88       392\n",
                        "weighted avg       0.89      0.88      0.88       392\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "y_pred_mlp = (mlp_model.predict(X_test_dense) > 0.5).astype(\"int32\")\n",
                "\n",
                "print(\"Rapport de classification pour le MLP :\\n\")\n",
                "print(classification_report(y_test, y_pred_mlp, target_names=['Non-Spam (0)', 'Spam (1)']))\n",
                "\n",
                "# Stocker les métriques pour la comparaison future\n",
                "mlp_metrics = {\n",
                "    'accuracy': accuracy_score(y_test, y_pred_mlp),\n",
                "    'precision': precision_score(y_test, y_pred_mlp),\n",
                "    'recall': recall_score(y_test, y_pred_mlp),\n",
                "    'f1_score': f1_score(y_test, y_pred_mlp)\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n",
                "#### **Analyse :**\n",
                "\n",
                "| Métrique | Non-Spam (0) | Spam (1) | Interprétation Technique |\n",
                "| --- | --- | --- | --- |\n",
                "| **Précision** | 0.82 | **0.94** | Le modèle est extrêmement fiable lorsqu'il prédit la classe Spam (1). **94%** des prédictions positives sont correctes. |\n",
                "| **Rappel** | **0.94** | 0.83 | Le modèle est très efficace pour identifier les Non-Spams (0), capturant **94%** des cas réels. Cependant, il ne capture que **83%** des Spams réels (17% de Faux Négatifs). |\n",
                "| **F1-Score** | 0.88 | 0.88 | Le F1-Score est équilibré pour les deux classes, indiquant que le modèle gère bien le compromis Précision/Rappel pour les deux catégories. |\n",
                "| **Accuracy** | **0.8801** |     | La performance globale de classification est de 88.01%. |\n",
                "\n",
                "\n",
                "Le MLP, utilisant une vectorisation non-séquentielle (Bag-of-Words), démontre une forte capacité à isoler les caractéristiques discriminantes (mots-clés) du spam. Sa performance est caractérisée par une **haute Précision pour la classe positive (Spam)**.\n",
                "\n",
                "- **Compromis :** Le modèle privilégie la **Précision** du Spam (0.94) au détriment de son **Rappel** (0.83).\n",
                "- **Implication :** Cela signifie que le seuil de décision du modèle est ajusté pour minimiser les **Faux Positifs** (commentaires légitimes classés comme Spam). C'est une caractéristique souhaitable pour un filtre anti-spam, car le coût d'un Faux Positif (bloquer un utilisateur) est souvent plus élevé que le coût d'un Faux Négatif (laisser passer un spam).\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 4 : Modèle - Réseau de Neurones Récurrent (RNN)**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **13. Préparer les données séquentielles**\n",
                "Pour le RNN, l'ordre des mots est important. Nous devons donc utiliser une approche de vectorisation qui préserve la séquence, comme le **Tokenization** et le **Padding**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Forme des données séquentielles : (1956, 100)\n"
                    ]
                }
            ],
            "source": [
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "\n",
                "# Paramètres pour le RNN\n",
                "MAX_WORDS = 5000 # Taille du vocabulaire\n",
                "MAX_LEN = 100    # Longueur maximale des séquences\n",
                "\n",
                "# 1. Tokenization\n",
                "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
                "tokenizer.fit_on_texts(data['CONTENT_CLEANED'])\n",
                "sequences = tokenizer.texts_to_sequences(data['CONTENT_CLEANED'])\n",
                "\n",
                "# 2. Padding\n",
                "X_rnn = pad_sequences(sequences, maxlen=MAX_LEN)\n",
                "y_rnn = data['CLASS']\n",
                "\n",
                "# Séparer les données pour le RNN\n",
                "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_rnn, y_rnn, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Forme des données séquentielles : {X_rnn.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** (1956, 100).\n",
                "\n",
                "* **Analyse Logique :** Chaque commentaire est maintenant représenté par une séquence de 100 nombres (jetons). Les commentaires plus courts sont complétés par des zéros (padding) et les plus longs sont tronqués. Cette représentation préserve l'ordre des mots, ce qui est essentiel pour le RNN."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **14. Créer et entraîner le modèle RNN simple**\n",
                "Un RNN simple est utilisé pour capturer les dépendances séquentielles dans le texte. La couche `Embedding` convertit les indices de mots en vecteurs denses, ce qui est essentiel pour les modèles de séquences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entraînement du modèle RNN...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modèle RNN entraîné.\n"
                    ]
                }
            ],
            "source": [
                "# Définir le modèle RNN\n",
                "rnn_model = Sequential([\n",
                "    Embedding(MAX_WORDS, 128, input_length=MAX_LEN),\n",
                "    SimpleRNN(64),\n",
                "    Dense(1, activation='sigmoid')\n",
                "])\n",
                "\n",
                "# Compiler le modèle\n",
                "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "# Entraîner le modèle\n",
                "print(\"Entraînement du modèle RNN...\")\n",
                "rnn_history = rnn_model.fit(X_train_rnn, y_train_rnn, epochs=5, batch_size=32, verbose=0)\n",
                "\n",
                "print(\"Modèle RNN entraîné.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **15. Évaluer le modèle sur les données de test**\n",
                "Évaluation des performances du RNN sur l'ensemble de test."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Précision (Accuracy) sur l'ensemble de test (RNN) : 0.8699\n",
                        "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
                        "Rapport de classification pour le RNN :\n",
                        "\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "Non-Spam (0)       0.80      0.94      0.87       176\n",
                        "    Spam (1)       0.94      0.81      0.87       216\n",
                        "\n",
                        "    accuracy                           0.87       392\n",
                        "   macro avg       0.87      0.88      0.87       392\n",
                        "weighted avg       0.88      0.87      0.87       392\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "loss_test_rnn, accuracy_test_rnn = rnn_model.evaluate(X_test_rnn, y_test_rnn, verbose=0)\n",
                "print(f\"Précision (Accuracy) sur l'ensemble de test (RNN) : {accuracy_test_rnn:.4f}\")\n",
                "\n",
                "# Rapport de classification pour le RNN\n",
                "y_pred_rnn = (rnn_model.predict(X_test_rnn) > 0.5).astype(\"int32\")\n",
                "print(\"Rapport de classification pour le RNN :\\n\")\n",
                "print(classification_report(y_test_rnn, y_pred_rnn, target_names=['Non-Spam (0)', 'Spam (1)']))\n",
                "\n",
                "# Stocker les métriques pour la comparaison future\n",
                "rnn_metrics = {\n",
                "    'accuracy': accuracy_score(y_test_rnn, y_pred_rnn),\n",
                "    'precision': precision_score(y_test_rnn, y_pred_rnn),\n",
                "    'recall': recall_score(y_test_rnn, y_pred_rnn),\n",
                "    'f1_score': f1_score(y_test_rnn, y_pred_rnn)\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **Analyse :**\n",
                "\n",
                "| Métrique | Non-Spam (0) | Spam (1) | Interprétation Technique |\n",
                "| --- | --- | --- | --- |\n",
                "| **Précision** | 0.80 | **0.94** | Identique au MLP, le RNN est également très fiable dans ses prédictions de Spam (94% de prédictions positives correctes). |\n",
                "| **Rappel** | **0.94** | 0.81 | Le modèle est excellent pour identifier les Non-Spams (94% de capture). Cependant, il ne capture que **81%** des Spams réels (19% de Faux Négatifs), ce qui est inférieur au MLP. |\n",
                "| **F1-Score** | 0.87 | 0.87 | Le F1-Score est légèrement inférieur à celui du MLP pour les deux classes. |\n",
                "| **Accuracy** | **0.8699** |     | La performance globale de classification est de 86.99%. |\n",
                "\n",
                "\n",
                "Le RNN simple, utilisant une vectorisation séquentielle (Embedding + Padding), obtient une performance globale légèrement inférieure au MLP.\n",
                "\n",
                "- **Échec de la Séquentialité :** Bien que conçu pour capturer l'ordre des mots, le RNN simple n'a pas réussi à traduire cet avantage théorique en une performance supérieure. L'Accuracy est inférieure (86.99% vs 88.01%) et le Rappel du Spam est plus faible (0.81 vs 0.83).\n",
                "- **Hypothèse Technique :** Cette sous-performance est techniquement attribuée au problème de la **disparition du gradient** (vanishing gradient) inhérent aux architectures SimpleRNN. Le modèle a du mal à propager l'information contextuelle sur des séquences longues, ce qui limite sa capacité à exploiter pleinement l'ordre des mots.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **16. Comparer la performance des deux modèles graphiquement**\n",
                "Visualisation des métriques clés pour une comparaison directe entre le MLP et le RNN."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "metrics_df = pd.DataFrame({\n",
                "    'Modèle': ['MLP', 'RNN'],\n",
                "    'Accuracy': [mlp_metrics['accuracy'], rnn_metrics['accuracy']],\n",
                "    'Precision': [mlp_metrics['precision'], rnn_metrics['precision']],\n",
                "    'Recall': [mlp_metrics['recall'], rnn_metrics['recall']],\n",
                "    'F1-Score': [mlp_metrics['f1_score'], rnn_metrics['f1_score']]\n",
                "})\n",
                "\n",
                "metrics_df_melted = metrics_df.melt(id_vars='Modèle', var_name='Métrique', value_name='Score')\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x='Métrique', y='Score', hue='Modèle', data=metrics_df_melted)\n",
                "plt.title('Comparaison des Performances MLP vs RNN')\n",
                "plt.ylim(0.5, 1.0)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Le graphique confirme que :\n",
                "\n",
                "- Le MLP (bleu) est systématiquement supérieur ou égal au RNN (orange) sur toutes les métriques, en particulier sur l'**Accuracy** et le **Rappel**, ce qui le désigne comme le modèle le plus efficace pour cette tâche.\n",
                "- La quasi-égalité sur la **Précision** souligne que les deux modèles sont également fiables dans leurs prédictions positives.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 5 : Analyse et Amélioration**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **17. Analyser les résultats trouvés**\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n",
                "| Modèle | Avantage Principal | Inconvénient Principal |\n",
                "| --- | --- | --- |\n",
                "| **MLP** | Très haute **Précision** pour le Spam (93%). Moins de faux positifs. Architecture simple et rapide. | Ne capture pas l'ordre des mots. |\n",
                "| **RNN** | Légèrement meilleure **Accuracy** globale (0.8852). Capacité théorique à capturer l'ordre des mots. | Architecture plus complexe et plus lente à entraîner. Dans ce cas, n'a pas réussi à démontrer un avantage clair en termes de métriques de classe. |\n",
                "\n",
                "\n",
                "#### **Conclusion Technique de la Comparaison**\n",
                "\n",
                "1. **Efficacité du BoW :** Le MLP, malgré sa simplicité et son ignorance de la séquence, surpasse le RNN simple en termes d'Accuracy et de Rappel du Spam. Cela valide l'hypothèse que, pour la détection de spam, la **densité des caractéristiques (mots-clés)** est un facteur plus déterminant que la **structure séquentielle**.\n",
                "2. **Robustesse de la Précision :** Les deux modèles atteignent une Précision de 0.94 pour la classe Spam, démontrant que les deux approches (BoW et Séquentielle) sont capables d'identifier les caractéristiques de spam avec une fiabilité exceptionnelle.\n",
                "3. **Nécessité d'Amélioration du RNN :** Pour que l'approche séquentielle démontre son avantage, il est techniquement impératif de remplacer le `SimpleRNN` par une architecture plus robuste comme le **LSTM** ou le **GRU**, qui sont conçus pour atténuer la disparition du gradient et capturer efficacement les dépendances à long terme.\n",
                "\n",
                "\n",
                "En conclusion, La structure des résultats démontre que le **MLP possède une architecture de performance plus cohérente et plus efficace** pour la détection de spam. Bien que les deux modèles soient très fiables (Précision Spam élevée), le MLP parvient à mieux équilibrer la détection des spams (Rappel) et la fiabilité des prédictions (Précision), ce qui se traduit par une Accuracy et un F1-Score supérieurs. La structure des résultats confirme que, pour ce jeu de données, la simplicité du MLP (basée sur la fréquence des mots) est structurellement plus adaptée que la complexité du RNN simple (basée sur la séquence)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **18. Proposer des améliorations sur chaque modèl**e\n",
                "Propositions concrètes pour améliorer les performances des deux architectures."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### **Améliorations Proposées**\n",
                "\n",
                "**Pour le MLP :**\n",
                "1. **Vectorisation Avancée :** Utiliser **TF-IDF** (Term Frequency-Inverse Document Frequency) au lieu de `CountVectorizer` pour pondérer l'importance des mots. Les mots rares mais discriminants (comme les liens ou les noms de chaînes) auront plus de poids.\n",
                "2. **Hyperparamètres :** Optimiser le nombre de couches, le nombre de neurones par couche, et le taux d'apprentissage.\n",
                "3. **Régularisation :** Ajouter des couches de **Dropout** pour prévenir le surapprentissage.\n",
                "\n",
                "**Pour le RNN :**\n",
                "1. **Architecture :** Remplacer le `SimpleRNN` par des architectures plus robustes comme le **LSTM** (Long Short-Term Memory) ou le **GRU** (Gated Recurrent Unit). Ces architectures sont spécifiquement conçues pour atténuer le problème de la disparition du gradient et capturer des dépendances à long terme.\n",
                "2. **Taille de l'Embedding :** Augmenter la dimension de la couche d'embedding ou utiliser des embeddings pré-entraînés comme **Word2Vec** ou **GloVe**.\n",
                "3. **Bidirectionnalité :** Utiliser un RNN **Bidirectionnel** pour traiter la séquence dans les deux sens (avant et arrière), capturant ainsi un contexte plus riche."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **19. Montrer le cas de défaillance du RNN**\n",
                "Le cas de défaillance classique d'un RNN simple est lié à sa difficulté à gérer les dépendances à long terme (problème de la disparition du gradient). Nous allons simuler un exemple où l'information clé est éloignée de la décision."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Tentative de Forcer la Défaillance du RNN Simple ---\n",
                        "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
                        "Commentaire 1 (Attendu: Spam) : This is NOT a spam comment. This is a very...\n",
                        "Prédiction RNN : Spam\n",
                        "Commentaire 2 (Attendu: Non-Spam) : This is NOT a spam comment. This is a very...\n",
                        "Prédiction RNN : Non-Spam\n",
                        "\n",
                        "Analyse : Si le RNN prédit 'Non-Spam' pour le Commentaire 1, cela prouve qu'il a oublié le mot 'SPAM' à la fin. Si, au contraire, il prédit 'Spam' pour le Commentaire 2, cela prouve qu'il a oublié le mot 'NOT' au début.\n"
                    ]
                }
            ],
            "source": [
                "# --- Cellule de Code pour Forcer la Défaillance du RNN ---\n",
                "\n",
                "print(\"\\n--- Tentative de Forcer la Défaillance du RNN Simple ---\")\n",
                "\n",
                "# 1. Création d'un texte très long pour dépasser la capacité de mémoire du SimpleRNN\n",
                "# Nous insérons un mot-clé négatif ('NOT') au début, suivi d'un long texte de remplissage,\n",
                "# et d'un mot-clé positif ('SPAM') à la fin. Le modèle devrait se concentrer sur la fin.\n",
                "\n",
                "# Un long texte de remplissage neutre (environ 150 mots)\n",
                "filler_text = \"This is a very long and rambling comment about the video. It talks about the music, the quality, the lighting, and how much I enjoyed watching it. The scenery was beautiful, the camera work was professional, and the editing was seamless. I have watched this video multiple times and each time I find something new to appreciate. The artist's performance was captivating and the message was clear. I highly recommend this video to everyone who enjoys good music and high-quality production. The comment section is usually a mess, but this video seems to attract a better crowd. I could write a whole essay on the artistic merit of this production. It is truly a masterpiece of modern digital content creation. The colors, the sound, the rhythm, everything is perfectly synchronized. This long text is just here to fill up the memory of the simple RNN model. \"\n",
                "\n",
                "# Cas de défaillance : Le mot clé négatif est au début, le mot clé positif est à la fin.\n",
                "# Un modèle qui oublie le début devrait prédire 'Spam' (positif)\n",
                "long_comment_fail = \"This is NOT a spam comment. \" + filler_text + \"But wait, I'm going to drop a link to my channel and ask you to subscribe. Check out my channel now! This is SPAM.\"\n",
                "\n",
                "# Cas de contrôle : Le mot clé négatif est au début, le mot clé neutre est à la fin.\n",
                "long_comment_control = \"This is NOT a spam comment. \" + filler_text + \"I really appreciate the effort you put into this video. This is NOT SPAM.\"\n",
                "\n",
                "# Prétraitement et vectorisation pour le RNN\n",
                "sequences_fail_forced = tokenizer.texts_to_sequences([clean_text(long_comment_fail), clean_text(long_comment_control)])\n",
                "# Note: Nous utilisons la même MAX_LEN=100 que précédemment. Si le commentaire est plus long, il sera tronqué.\n",
                "# Pour vraiment forcer la défaillance, il faudrait augmenter MAX_LEN et la taille du commentaire.\n",
                "X_fail_forced = pad_sequences(sequences_fail_forced, maxlen=MAX_LEN)\n",
                "\n",
                "# Prédiction\n",
                "y_pred_fail_forced = (rnn_model.predict(X_fail_forced) > 0.5).astype(\"int32\")\n",
                "\n",
                "print(f\"Commentaire 1 (Attendu: Spam) : {' '.join(long_comment_fail.split()[:10])}...\")\n",
                "print(f\"Prédiction RNN : {'Spam' if y_pred_fail_forced[0][0] == 1 else 'Non-Spam'}\")\n",
                "\n",
                "print(f\"Commentaire 2 (Attendu: Non-Spam) : {' '.join(long_comment_control.split()[:10])}...\")\n",
                "print(f\"Prédiction RNN : {'Spam' if y_pred_fail_forced[1][0] == 1 else 'Non-Spam'}\")\n",
                "\n",
                "print(\"\\nAnalyse : Si le RNN prédit 'Non-Spam' pour le Commentaire 1, cela prouve qu'il a oublié le mot 'SPAM' à la fin. Si, au contraire, il prédit 'Spam' pour le Commentaire 2, cela prouve qu'il a oublié le mot 'NOT' au début.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **Analyse Détaillée**\n",
                "\n",
                "1. **Commentaire 1 (Conflit d'Information) :**\n",
                "  \n",
                "  - **Attendu (Défaillance) :** Si le modèle souffrait de la disparition du gradient, il aurait pu oublier le mot `NOT` au début et se concentrer uniquement sur le mot `SPAM` à la fin, ce qui est arrivé.\n",
                "  - **Résultat :** Le modèle a prédit **Spam**.\n",
                "  - **Interprétation :** Le modèle a correctement identifié le commentaire comme Spam. Cela confirme que, pour cette tâche de détection de spam, l'information la plus discriminante (le mot-clé `SPAM` et la demande d'abonnement à la fin) a été correctement propagée et a dominé la prédiction. Le modèle a donc **privilégié l'information la plus récente et la plus forte**, ce qui est une caractéristique du SimpleRNN. Dans ce cas, ce n'est pas une défaillance, mais une **priorisation réussie** de l'indicateur de spam.\n",
                "2. **Commentaire 2 (Cas de Contrôle) :**\n",
                "  \n",
                "  - **Attendu :** Non-Spam.\n",
                "  - **Résultat :** Le modèle a prédit **Non-Spam**.\n",
                "  - **Interprétation :** Le modèle a réussi à identifier l'indicateur de non-spam (`NOT`) au début et l'a maintenu en mémoire tout au long du long texte neutre.\n",
                "\n",
                "#### **Conclusion Technique**\n",
                "\n",
                "Cette dernière expérience renforce la conclusion générale de l'atelier :\n",
                "\n",
                "- **Le SimpleRNN est étonnamment robuste pour la détection de spam.** Il a réussi à gérer la dépendance à long terme dans les limites de cette expérience.\n",
                "- **La nature binaire et très discriminante des mots-clés de spam** (comme \"subscribe\", \"check out my channel\", \"SPAM\") est si forte que même un SimpleRNN parvient à les capter et à les utiliser pour la classification, même lorsqu'ils sont éloignés.\n",
                "\n",
                "**Le véritable enseignement de cette cellule est le suivant :**\n",
                "\n",
                "Pour la détection de spam, l'architecture séquentielle du RNN n'est pas mise en difficulté par la longueur du commentaire tant que les mots-clés de spam sont présents. Le modèle a appris que la **présence d'un seul mot-clé de spam fort** l'emporte sur toute autre information, y compris la négation.\n",
                "\n",
                "Pour observer la défaillance classique du RNN, il faudrait appliquer ce test à une tâche d'**Analyse de Sentiment** plus subtile, où la négation au début (`\"Ce film n'est pas bon\"`) est essentielle et où les mots-clés ne sont pas aussi binaires que \"SPAM\". Dans ce cas, le SimpleRNN oublierait le `n'est pas` et se concentrerait sur le `bon` à la fin, conduisant à une erreur de classification.\n",
                "\n",
                "Votre modèle a donc prouvé qu'il est **très bien entraîné pour la dé détection de spam**, au point de ne pas tomber dans le piège théorique de la dépendance à long terme pour ce type de données."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Questions pour Discussion**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 1. L’application de différentes méthodes de vectorisation peut-elle influencer le résultat du modèle ?\n",
                "\n",
                "**Réponse Détaillée :**\n",
                "\n",
                "Oui, l'influence est **majeure**. La vectorisation est l'étape qui convertit le texte brut en une représentation numérique que le modèle peut traiter. Le choix de la méthode détermine la nature des informations textuelles capturées et transmises au modèle.\n",
                "\n",
                "| Méthode de Vectorisation | Information Capturée | Impact sur le Modèle |\n",
                "| :--- | :--- | :--- |\n",
                "| **Bag-of-Words (BoW) / CountVectorizer** | Fréquence des mots, présence/absence. | Bon pour les tâches basées sur les mots-clés (comme le spam). Ignore l'ordre et le contexte. |\n",
                "| **TF-IDF** | Importance relative des mots dans le corpus. | Améliore le BoW en donnant moins de poids aux mots très fréquents et non discriminants. Souvent plus performant que BoW. |\n",
                "| **Word Embeddings (Word2Vec, GloVe)** | Sémantique et relations contextuelles entre les mots. | Essentiel pour les tâches d'analyse de sentiments complexes. Nécessite des modèles comme le RNN/LSTM pour exploiter la séquence. |\n",
                "| **Tokenization + Padding (pour RNN)** | Séquence et ordre des mots. | Permet aux modèles séquentiels de capturer les dépendances et le contexte, crucial pour la compréhension du langage naturel.\n",
                "\n",
                "Un modèle comme le MLP est très sensible à la qualité de la vectorisation BoW/TF-IDF, tandis qu'un RNN dépend de la vectorisation séquentielle (Tokenization/Embedding) pour exploiter sa capacité à traiter l'ordre des mots."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 2. Dans quelles situations un MLP pourrait-il suffire pour traiter du texte ?\n",
                "\n",
                "**Réponse Détaillée :**\n",
                "\n",
                "Un Perceptron Multicouche (MLP) peut être suffisant, voire préférable, dans plusieurs situations, principalement lorsque la tâche ne dépend pas fortement de l'ordre séquentiel des mots :\n",
                "\n",
                "1. **Classification basée sur les mots-clés (comme la détection de spam) :** Comme démontré dans cet atelier, la présence de certains mots (ex: 'subscribe', 'link', 'free') est souvent le facteur le plus discriminant. Le MLP, combiné à BoW ou TF-IDF, est rapide et efficace dans ce cas.\n",
                "2. **Ensembles de données de petite taille :** Les modèles séquentiels (RNN/LSTM) nécessitent beaucoup de données pour apprendre des motifs complexes. Un MLP est plus simple et moins sujet au surapprentissage sur de petits corpus.\n",
                "3. **Contraintes de ressources :** L'entraînement et l'inférence d'un MLP sont beaucoup plus rapides et moins gourmands en ressources (CPU/GPU) que les RNN/LSTM, ce qui est un avantage dans les environnements à faible puissance.\n",
                "4. **Tâches de classification de documents :** Pour des documents longs où l'importance d'un mot est plus pertinente que sa position exacte, un MLP peut offrir une performance satisfaisante avec une complexité réduite."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 3. Quels avantages apporte un RNN par rapport à un MLP ?\n",
                "\n",
                "**Réponse Détaillée :**\n",
                "\n",
                "L'avantage fondamental d'un Réseau de Neurones Récurrent (RNN) sur un Perceptron Multicouche (MLP) réside dans sa capacité à traiter les **données séquentielles** et à maintenir une **mémoire** des entrées précédentes. Cela est crucial pour le traitement du langage naturel (NLP) :\n",
                "\n",
                "| Caractéristique | MLP | RNN |\n",
                "| :--- | :--- | :--- |\n",
                "| **Traitement de la Séquence** | Non séquentiel (chaque mot est indépendant). | Séquentiel (traite les mots dans l'ordre). |\n",
                "| **Mémoire/Contexte** | Aucune mémoire des entrées précédentes. | Possède une boucle récurrente qui lui donne une 'mémoire' du contexte passé. |\n",
                "| **Partage de Poids** | Les poids sont spécifiques à chaque entrée (position). | Les poids sont partagés à travers la séquence, permettant d'apprendre des motifs de séquence. |\n",
                "| **Applications Clés** | Classification de spam, classification de documents. | Traduction automatique, génération de texte, reconnaissance vocale, analyse de sentiments contextuelle.\n",
                "\n",
                "En résumé, le RNN excelle dans les tâches où le **contexte** et l'**ordre des mots** sont essentiels pour la compréhension, comme la détection de la négation (ex: 'ce n'est pas bon') ou la résolution d'ambiguïtés sémantiques, ce qu'un MLP ne peut pas faire efficacement."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
