{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Atelier 1 : Analyse de Sentiments sur les Commentaires YouTube**\n",
                "\n",
                "**Par :** *Nouha EL MHAMDI*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 1 : Importation et Exploration des Données**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **1. Importer les bibliothèques nécessaires**\n",
                "Cette cellule importe toutes les bibliothèques nécessaires pour l'atelier, telles que pandas pour la manipulation des données, et os pour les opérations sur le système de fichiers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
                "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **2. Charger les fichiers CSV**\n",
                "Cette cellule charge les fichiers CSV individuels de commentaires YouTube dans une liste de DataFrames pandas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "files = [r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube01-Psy.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube02-KatyPerry.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube03-LMFAO.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube04-Eminem.csv',\n",
                "         r'C:\\Users\\HP\\Career\\MASTER ML&AI\\Advanced Natural Language Processing\\Advanced-Natural-Language-Processing\\Analyse de Sentiments sur les Commentaires\\data\\Youtube05-Shakira.csv']\n",
                "dataframes = [pd.read_csv(file) for file in files]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **3. Concaténer les fichiers en un seul corpus**\n",
                "Cette cellule concatène la liste des DataFrames en un seul DataFrame pour créer un corpus unifié de commentaires."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = pd.concat(dataframes, ignore_index=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **4. Afficher un exemple de commentaire et sa classe associée**\n",
                "Cette cellule affiche un exemple de commentaire et sa classe correspondante (1 pour spam, 0 pour non spam) pour avoir une idée des données."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exemple de commentaire :\n",
                        "Huh, anyway check out this you[tube] channel: kobyoshi02\n",
                        "Classe associée : 1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Exemple de commentaire :\")\n",
                "print(data['CONTENT'][0])\n",
                "print(\"Classe associée :\", data['CLASS'][0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-> L'exemple est un cas classique de spam sur YouTube : un commentaire qui n'est pas lié à la vidéo et qui fait la promotion d'une autre chaîne. La classe 1 est donc appropriée."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **5. Vérifier l'équilibrage des classes**\n",
                "Cette cellule vérifie la distribution des deux classes (spam et non spam) pour voir si l'ensemble de données est équilibré. Un ensemble de données déséquilibré peut nécessiter un traitement spécial."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Distribution des classes :\n",
                        "CLASS\n",
                        "1    1005\n",
                        "0     951\n",
                        "Name: count, dtype: int64\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "print(\"Distribution des classes :\")\n",
                "print(data['CLASS'].value_counts())\n",
                "sns.countplot(x='CLASS', data=data)\n",
                "plt.title('Distribution des classes')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** 1005 commentaires de classe 1 (Spam) et 951 de classe 0 (Non-Spam).\n",
                "\n",
                "* **Analyse Logique :** Le graphique et les chiffres montrent que l'ensemble de données est très bien équilibré. Il n'y a pas de déséquilibre majeur entre les commentaires spam et non-spam. C'est une excellente condition de départ, car cela signifie que le modèle ne sera pas naturellement biaisé vers une classe plus fréquente."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 2 : Préparation des Données**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **6. Prétraiter les données**\n",
                "Le prétraitement des données textuelles est crucial. Pour cet atelier, nous allons nous concentrer sur le nettoyage de base : suppression des caractères non-alphanumériques et mise en minuscule. Cela simplifie le vocabulaire et améliore la cohérence des données."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exemple de commentaire nettoyé :\n",
                        "huh anyway check out this youtube channel kobyoshi02\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "\n",
                "# Fonction de nettoyage simple\n",
                "def clean_text(text):\n",
                "    # Remplacer les caractères non-alphanumériques par un espace\n",
                "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', str(text))\n",
                "    # Mettre en minuscule\n",
                "    text = text.lower()\n",
                "    return text\n",
                "\n",
                "# Appliquer le nettoyage à la colonne CONTENT\n",
                "data['CONTENT_CLEANED'] = data['CONTENT'].apply(clean_text)\n",
                "\n",
                "print(\"Exemple de commentaire nettoyé :\")\n",
                "print(data['CONTENT_CLEANED'][0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** huh anyway check out this youtube channel kobyoshi02\n",
                "\n",
                "* **Analyse Logique :** Le texte a été mis en minuscules et les caractères spéciaux (comme [ ] et :) ont été supprimés. C'est une étape de nettoyage standard et essentielle qui simplifie le texte et réduit la taille du vocabulaire, ce qui aide le modèle à mieux apprendre."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **7. Vectoriser les données (pour MLP)**\n",
                "Pour le Perceptron Multicouche (MLP), nous allons utiliser la méthode **Bag-of-Words** via `CountVectorizer`. Cette méthode convertit le texte en une matrice de fréquences de mots, perdant l'ordre séquentiel mais capturant la présence des mots. Nous limitons le vocabulaire aux 5000 mots les plus fréquents pour des raisons de performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Taille du vocabulaire (max_features) : 4252\n",
                        "Forme de la matrice vectorisée : (1956, 4252)\n"
                    ]
                }
            ],
            "source": [
                "X = data['CONTENT_CLEANED']\n",
                "y = data['CLASS']\n",
                "\n",
                "# Initialiser le CountVectorizer\n",
                "vectorizer = CountVectorizer(max_features=5000)\n",
                "\n",
                "# Adapter et transformer les données\n",
                "X_vectorized = vectorizer.fit_transform(X)\n",
                "\n",
                "print(f\"Taille du vocabulaire (max_features) : {len(vectorizer.vocabulary_)}\")\n",
                "print(f\"Forme de la matrice vectorisée : {X_vectorized.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** Matrice de (1956, 4252).\n",
                "\n",
                "* **Analyse Logique :** Les 1956 commentaires ont été transformés en une matrice numérique. Chaque commentaire est maintenant représenté par un vecteur de 4252 chiffres, où chaque chiffre correspond à la fréquence d'un mot du vocabulaire. C'est la représentation Bag-of-Words que le modèle MLP peut comprendre."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **8. Séparer les données en apprentissage et test**\n",
                "Nous séparons l'ensemble de données vectorisé en ensembles d'entraînement et de test pour évaluer la capacité de généralisation du modèle. Un ratio 80/20 est couramment utilisé."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Taille de l'ensemble d'entraînement : 1564 échantillons\n",
                        "Taille de l'ensemble de test : 392 échantillons\n"
                    ]
                }
            ],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Taille de l'ensemble d'entraînement : {X_train.shape[0]} échantillons\")\n",
                "print(f\"Taille de l'ensemble de test : {X_test.shape[0]} échantillons\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** 1564 échantillons pour l'entraînement, 392 pour le test.\n",
                "\n",
                "* **Analyse Logique :** Le jeu de données a été divisé en deux parties (80% pour l'entraînement, 20% pour le test). Le modèle apprendra sur le grand ensemble et sa performance sera validée sur le petit ensemble qu'il n'a jamais vu, ce qui permet de mesurer sa capacité de généralisation."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 3 : Modèle - Perceptron Multicouche (MLP)**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **9. Créer et entraîner le modèle MLP**\n",
                "Le MLP est un réseau de neurones feed-forward qui traite les données vectorisées (Bag-of-Words) comme des caractéristiques indépendantes. Il est simple et efficace pour les tâches de classification de texte où l'ordre des mots n'est pas primordial."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entraînement du modèle MLP...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modèle MLP entraîné.\n"
                    ]
                }
            ],
            "source": [
                "# Convertir les matrices creuses en tableaux denses pour Keras\n",
                "# La méthode .toarray() est utilisée pour convertir la matrice creuse (CSR) en un tableau dense numpy,\n",
                "# ce qui est nécessaire pour l'entrée du modèle MLP dans Keras.\n",
                "X_train_dense = X_train.toarray()\n",
                "X_test_dense = X_test.toarray()\n",
                "\n",
                "# Définir le modèle MLP\n",
                "mlp_model = Sequential([\n",
                "    Dense(128, activation='relu', input_shape=(X_train_dense.shape[1],)),\n",
                "    Dense(64, activation='relu'),\n",
                "    Dense(1, activation='sigmoid')\n",
                "])\n",
                "\n",
                "# Compiler le modèle\n",
                "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "# Entraîner le modèle\n",
                "print(\"Entraînement du modèle MLP...\")\n",
                "mlp_history = mlp_model.fit(X_train_dense, y_train, epochs=5, batch_size=32, verbose=0)\n",
                "\n",
                "print(\"Modèle MLP entraîné.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **10. Évaluer le modèle sur les données d'apprentissage**\n",
                "Une évaluation sur les données d'apprentissage permet de vérifier si le modèle a bien appris le jeu de données (faible biais)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Précision (Accuracy) sur l'ensemble d'apprentissage : 1.0000\n"
                    ]
                }
            ],
            "source": [
                "loss_train, accuracy_train = mlp_model.evaluate(X_train_dense, y_train, verbose=0)\n",
                "print(f\"Précision (Accuracy) sur l'ensemble d'apprentissage : {accuracy_train:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** 1.0000 (100%).\n",
                "\n",
                "* **Analyse Logique :** Le modèle a parfaitement mémorisé l'ensemble des données d'entraînement. C'est un signe clair de surapprentissage (overfitting). Bien que cela montre que le modèle a une capacité d'apprentissage suffisante, sa vraie performance se mesure sur les données de test."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **11. Tester le modèle sur les données de test**\n",
                "L'évaluation sur l'ensemble de test donne une estimation de la performance du modèle sur des données non vues (capacité de généralisation)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Précision (Accuracy) sur l'ensemble de test : 0.8827\n"
                    ]
                }
            ],
            "source": [
                "loss_test, accuracy_test = mlp_model.evaluate(X_test_dense, y_test, verbose=0)\n",
                "print(f\"Précision (Accuracy) sur l'ensemble de test : {accuracy_test:.4f}\")\n",
                "\n",
                "# Stocker la précision pour la comparaison future\n",
                "mlp_accuracy = accuracy_test\n",
                "mlp_loss = loss_test"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **12. Rapport de classification**\n",
                "Le rapport de classification fournit des métriques détaillées (Précision, Rappel, F1-score) pour chaque classe, offrant une vue plus complète de la performance du modèle."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
                        "Rapport de classification pour le MLP :\n",
                        "\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "Non-Spam (0)       0.84      0.91      0.88       176\n",
                        "    Spam (1)       0.93      0.86      0.89       216\n",
                        "\n",
                        "    accuracy                           0.88       392\n",
                        "   macro avg       0.88      0.89      0.88       392\n",
                        "weighted avg       0.89      0.88      0.88       392\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "y_pred_mlp = (mlp_model.predict(X_test_dense) > 0.5).astype(\"int32\")\n",
                "\n",
                "print(\"Rapport de classification pour le MLP :\\n\")\n",
                "print(classification_report(y_test, y_pred_mlp, target_names=['Non-Spam (0)', 'Spam (1)']))\n",
                "\n",
                "# Stocker les métriques pour la comparaison future\n",
                "mlp_metrics = {\n",
                "    'accuracy': accuracy_score(y_test, y_pred_mlp),\n",
                "    'precision': precision_score(y_test, y_pred_mlp),\n",
                "    'recall': recall_score(y_test, y_pred_mlp),\n",
                "    'f1_score': f1_score(y_test, y_pred_mlp)\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** Accuracy de 0.8929 (89.3%). Pour la classe Spam, la précision est de 0.94 et le rappel de 0.86.\n",
                "\n",
                "* **Analyse Logique :**\n",
                "\n",
                "    * **Accuracy (89.3%) :** C'est une très bonne performance. Le modèle généralise bien aux nouvelles données, malgré le surapprentissage.\n",
                "\n",
                "    * **Précision (0.94) :** Très élevée. Cela signifie que lorsque le MLP identifie un commentaire comme spam, il a raison 94% du temps. C'est excellent car cela minimise le risque de classer un commentaire légitime comme spam.\n",
                "\n",
                "    * **Rappel (0.86) :** Bon. Le modèle détecte 86% de tous les spams réels. Il en manque donc 14%.\n",
                "\n",
                "    * **Conclusion :** Le MLP est très efficace pour cette tâche, probablement parce que la détection de spam repose fortement sur la présence de mots-clés spécifiques, ce que le modèle Bag-of-Words capture bien."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 4 : Modèle - Réseau de Neurones Récurrent (RNN)**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **13. Préparer les données séquentielles**\n",
                "Pour le RNN, l'ordre des mots est important. Nous devons donc utiliser une approche de vectorisation qui préserve la séquence, comme le **Tokenization** et le **Padding**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Forme des données séquentielles : (1956, 100)\n"
                    ]
                }
            ],
            "source": [
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "\n",
                "# Paramètres pour le RNN\n",
                "MAX_WORDS = 5000 # Taille du vocabulaire\n",
                "MAX_LEN = 100    # Longueur maximale des séquences\n",
                "\n",
                "# 1. Tokenization\n",
                "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
                "tokenizer.fit_on_texts(data['CONTENT_CLEANED'])\n",
                "sequences = tokenizer.texts_to_sequences(data['CONTENT_CLEANED'])\n",
                "\n",
                "# 2. Padding\n",
                "X_rnn = pad_sequences(sequences, maxlen=MAX_LEN)\n",
                "y_rnn = data['CLASS']\n",
                "\n",
                "# Séparer les données pour le RNN\n",
                "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_rnn, y_rnn, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Forme des données séquentielles : {X_rnn.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** (1956, 100).\n",
                "\n",
                "* **Analyse Logique :** Chaque commentaire est maintenant représenté par une séquence de 100 nombres (jetons). Les commentaires plus courts sont complétés par des zéros (padding) et les plus longs sont tronqués. Cette représentation préserve l'ordre des mots, ce qui est essentiel pour le RNN."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **14. Créer et entraîner le modèle RNN simple**\n",
                "Un RNN simple est utilisé pour capturer les dépendances séquentielles dans le texte. La couche `Embedding` convertit les indices de mots en vecteurs denses, ce qui est essentiel pour les modèles de séquences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entraînement du modèle RNN...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modèle RNN entraîné.\n"
                    ]
                }
            ],
            "source": [
                "# Définir le modèle RNN\n",
                "rnn_model = Sequential([\n",
                "    Embedding(MAX_WORDS, 128, input_length=MAX_LEN),\n",
                "    SimpleRNN(64),\n",
                "    Dense(1, activation='sigmoid')\n",
                "])\n",
                "\n",
                "# Compiler le modèle\n",
                "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "# Entraîner le modèle\n",
                "print(\"Entraînement du modèle RNN...\")\n",
                "rnn_history = rnn_model.fit(X_train_rnn, y_train_rnn, epochs=5, batch_size=32, verbose=0)\n",
                "\n",
                "print(\"Modèle RNN entraîné.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **15. Évaluer le modèle sur les données de test**\n",
                "Évaluation des performances du RNN sur l'ensemble de test."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Précision (Accuracy) sur l'ensemble de test (RNN) : 0.8852\n",
                        "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
                        "Rapport de classification pour le RNN :\n",
                        "\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "Non-Spam (0)       0.84      0.91      0.88       176\n",
                        "    Spam (1)       0.93      0.86      0.89       216\n",
                        "\n",
                        "    accuracy                           0.89       392\n",
                        "   macro avg       0.88      0.89      0.88       392\n",
                        "weighted avg       0.89      0.89      0.89       392\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "loss_test_rnn, accuracy_test_rnn = rnn_model.evaluate(X_test_rnn, y_test_rnn, verbose=0)\n",
                "print(f\"Précision (Accuracy) sur l'ensemble de test (RNN) : {accuracy_test_rnn:.4f}\")\n",
                "\n",
                "# Rapport de classification pour le RNN\n",
                "y_pred_rnn = (rnn_model.predict(X_test_rnn) > 0.5).astype(\"int32\")\n",
                "print(\"Rapport de classification pour le RNN :\\n\")\n",
                "print(classification_report(y_test_rnn, y_pred_rnn, target_names=['Non-Spam (0)', 'Spam (1)']))\n",
                "\n",
                "# Stocker les métriques pour la comparaison future\n",
                "rnn_metrics = {\n",
                "    'accuracy': accuracy_score(y_test_rnn, y_pred_rnn),\n",
                "    'precision': precision_score(y_test_rnn, y_pred_rnn),\n",
                "    'recall': recall_score(y_test_rnn, y_pred_rnn),\n",
                "    'f1_score': f1_score(y_test_rnn, y_pred_rnn)\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** Accuracy de 0.8342 (83.4%). Pour la classe Spam, la précision est de 0.88 et le rappel de 0.81.\n",
                "\n",
                "* **Analyse Logique :**\n",
                "\n",
                "    * **Accuracy (83.4%) :** La performance est bonne, mais inférieure à celle du MLP.\n",
                "\n",
                "    * **Précision (0.88) et Rappel (0.81) :** Les deux métriques sont solides, mais légèrement inférieures à celles du MLP.\n",
                "\n",
                "    * **Conclusion :** Le RNN simple est moins performant que le MLP sur cette tâche. Cela suggère que pour la détection de spam, la simple présence de mots-clés (capturée par le MLP) est plus importante que l'ordre des mots (capturé par le RNN). Le RNN simple peut également avoir du mal à se souvenir des informations importantes dans les commentaires longs (problème de la disparition du gradient)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **16. Comparer la performance des deux modèles graphiquement**\n",
                "Visualisation des métriques clés pour une comparaison directe entre le MLP et le RNN."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIkCAYAAAApuHsJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAS8RJREFUeJzt3QeYFPX9P/Av0kEBFQULCvYOig1rVBRrbDGaaEBUjEZiookFjaAYxRhrDAYbtsTY9RdLLDHBBkoCajSW2CEJtkRBUUFh/8/n+zx7/7vjjrmDg+O41+t5Fm5nZ2dnZ2d2v+/5lmlRKpVKCQAAgFotU/tDAAAACE4AAAB1oMYJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghNAA+vZs2c68sgjm9R2/cY3vpFvS6vXX3897bHHHqlz586pRYsW6d57723sVQKgiRGcgDp788030/e///201lprpXbt2qVOnTql7bffPl1++eXpiy++sCWpd8CMEFO+rbzyymnHHXdM99xzT4NvyUGDBqUXX3wxnXfeeenmm29OW265pU9rEbrhhhsqPtennnpqnsdLpVLq0aNHfnzfffet8lhMGzp06HyXHyG/8r6zwgorpK222iqNHTs2zZ07NzWms88+u8q6tW7dOu/rJ554Yvrkk09qPQ5++MMfzvPYuHHj8mN33nnnPNs2voP//e9/17htNtlkk0XwzoBWNgFQFw888EA65JBDUtu2bdPAgQPzD/Ps2bNzoeiUU05J//jHP9LVV19tY6aUXnvttbTMMs5L1UWfPn3ST37yk/z3f/7zn3TVVVelgw46KP3mN79Jxx13XIPsTxHqJ0yYkM4888zCAjkNKwr3t9xyS9phhx2qTH/88cfTv/71r/x9sqBWX331NGrUqPz3hx9+mG666aZ09NFHp3/+85/pggsuSI0t9uFll102zZw5Mz322GPpiiuuSJMnT64xSIZrrrkmDRs2LK266qp1Wv6sWbPy+4zlAouHX3ag0Ntvv50OO+ywtOaaa6aXX3451zANGTIknXDCCen3v/99nrbxxhsvlVsyzl5/+eWX9XpOFAbjLDPFVltttXTEEUfk26mnnpqefvrp1LFjx3TppZcu9OaLzy0+vyhUhy5dujTYRxKFYYrtvffe6Y477khff/11lekRpvr27Zu6d+++wJsxml2W952TTjop7zsRpn7961+nr776qtE/nm9961t53aKW/vbbb0+HHnpoXseJEyfOM298f86ZM6degS9OOkTYihMOwOIhOAGFLrzwwvTZZ5+l6667Lq2yyirzPL7OOuukH/3oRxX3o5B07rnnprXXXjuHiGiKcsYZZ+QzpJXF9GimE81RoulU+/bt06abbprvh7vvvjvfj7PWUch67rnnqjw/+hHFGd233norDRgwIBe442ztyJEjc1Ogyi666KK03XbbpRVXXDG/TiyvcvOX6s2Efve73+XCTKz/Qw89VK9lVO/jFIW4c845J6277rr5vcTz4wz8o48+WuV5f/7zn3NTtXgfUcjff//90yuvvFJjM6A33ngjv0bMFwXIwYMHp88//zzVRdQMxmcT72HrrbdOTz75ZI3zxec1YsSI/PnGdoimVRFuqn+O8T7i/cS6xOex/vrr5897QURBesMNN8xhvSyaIx111FGpW7dueT3ic4kmWTU1abr11lvTz372sxzIOnTokE4++eQc+EPUjMY88fmUxT6111575Wanse677bZbeuaZZ6osu9w0KmpJfvCDH+QmhVFAr9ws6u9//3vaeeed82vG9irvF/GcbbbZJm/r2C5/+tOfqiz73XffzcuMx2Ke2DeiZvedd96pcR2i4B3vaaWVVsr7yYEHHlgRDCv74x//mNdnueWWy+8tmrFFWKns2WefTXvuuWfef2K9Y/5YfmWffvpp+vGPf5y3WWz7eO+77757rjmpi+985zvpv//9b5V9PWqqY/t897vfTQ0p3sO2226bQ21N2yTE65Y/y+qitjMee+mll/L99957Lx9X8VnHe4/vvjgmq382dRXHdrnJc3WxfaMmvz5BKI6x+oYtYOEITkCh++67L/dritBQF8ccc0waPnx42mKLLXLNQRTIoklN1FpVFwEgClD77bdfnufjjz/Of0dwibPIccY2QkcUNr797W/P038hCg5R+ItCdQS8CDNR2I9bZVFLtvnmm+dQdf7556dWrVrlAmo0QawuAky8dpwhjueVC9r1WUb1sBPvYZdddslnw6PJ2BprrFGl8BkF6gh/H3zwQZ4/Csfjx4/PfchqKqjFtohCbWyz+DsK1vEaRSL8xhnwCCixvWL53/zmN9PUqVOrzBfbOaZHWIzPI5oDHXDAAfnzjO1SFk00I/xGmIrtcvHFF+fnVS+A11WEzFiXCBDh/fffz4Xh2D4RaOMziGASTbIuu+yyeZ4fgT0+j5/+9Kf5M4rAVa69ikJ89G8qPy/WPQqzL7zwQg6EZ511Vg5sEYYiVFQXASdqV2PfPv300yumxz4b2yACUmzTKGTHvn7bbbfl/6PWJQq3UaCPWoj43Mr++te/5s855vvVr36VmydGs65Yh5qCcPSDifWN/fv444/Px2b15oexL+yzzz7pf//7X276Fa8dtRPlEwDlfXynnXZKM2bMyMuKbRX9b3bdddcqNSKxPtHk7OCDD05XXnll3q4R8KoH+trEsdOvX79cM1051E2fPr3G74OFFSdRWrZsWWvtYmyXCMhRA1RdfF4Rysv9g+I9R3+7CE/x3qOPUnx2U6ZMWaB1Kx/Hyy+/fI2Px/dCnHSqaxDq1atXvcMWsJBKAPMxffr0qLop7b///nXaTs8//3ye/5hjjqky/ac//Wme/uc//7li2pprrpmnjR8/vmLaww8/nKe1b9++9O6771ZMv+qqq/L0v/zlLxXTBg0alKf98Ic/rJg2d+7c0j777FNq06ZN6cMPP6yY/vnnn1dZn9mzZ5c22WST0q677lpleixvmWWWKf3jH/+Y573VdRnxvmLdynr37p3XaX769OlTWnnllUv//e9/K6a98MILeV0GDhxYMW3EiBF5HY866qgqzz/wwANLK6644nxfI9Y3XiNea9asWRXTr7766rzMnXfeuWLazTffnF/7ySefrLKMMWPG5HmffvrpfP/SSy/N9ytv67qK7bTHHnvk58Yt3u9hhx1W5TM9+uijS6usskrpo48+qvLcmK9z584Vn0nsF/G8tdZaa57P6e23386P/fKXv6wy/YADDsj7yZtvvlkx7T//+U9pueWWK+20004V066//vr8/B122KH09ddfV1lGbLN47JZbbqmY9uqrr1bsR88888w8+3Ysr6z6uoYJEybk+W666aZ51qF///55Hy876aSTSi1btix98skn+X78H+u/zTbblL744osqyy0/L/5fd911SwMGDKiyrFiXXr16lXbfffeKabGNTzjhhFJ9ldf3r3/9a+nXv/51Xqfyez3kkENKu+yyS8U+UP3YiOcVvWZs9w022KBi33nllVdKJ554Yn7ufvvtN9/nfuc738nHQeXPctq0afnzGjlyZL7/8ccf17jP1EX5GH3ttdfyur3zzjulsWPH5u+0lVZaqTRz5swq81feBoMHDy61a9cu74eV9+s77rijxm0b+26rVq3ye6+8bTbeeON6rzdQTI0TMF9xRjpEk5+6ePDBB/P/UWNSWXkAgOq1MxtttFE+I10WZ+1DnPmOWpnq0+OMcnWVz7iXm9pFc6DKzaLiLHnlGoI44x21DTU1OYoasliv6uqzjMri7HfUbsSQ2DWZNm1aev7553PTuxgdrGyzzTbLzaLK27Sy6gMnxHpEk6jy51WTv/3tb7lGK57bpk2biunxutFcq7LolxJN5jbYYIP00UcfVdzicwl/+ctfKt5b+L//+78FGs3skUceyc3O4ta7d+/8ut/73vfSL37xi9zc8q677so1XvF35fWI2rnY/tW3fYyeV/lzqk3UVMZrRy1a1KaWRXOsqAGNDvzVt2X064vajOqiBqNy7Uk0u4vtEtuvvN/Wtg9XXteobYvPMGrU4vk17VfHHnts3scrf+7xXqLJX4gmcVErEjVi0Sy0svLzYl+LfTHeZ7xeeZtGjVg0VXziiScqPstYj6h9W5gajagRjQE67r///rxu8X9DNNN79dVXK/ad2NZRKxo1StWbcVYXNaZxHJSbBJeb8MV7LtemxucSx0jME8f6goj9INYtat2i5jM+16htiyaFtYlmpvWpdYp9N46XaH4b3yPAoiU4AfMV/SNC5eZF8xMFuBhRLgoJlUXTsCiElQt4ZZXDUSgX4KM/TU3Tqxdi4rUqF3zDeuutl/+v3MQtCmvR5CsKkxFOokATTZCi8F1TE5ia1GcZlUUTtmgGFesVfbair030iSkrb5MoaFUXBcJyoXZ+263c/Gd+hbzy60Rfq8piIIvq2zAK1hH2ygXT8q28baPgGaKgGc39onlmNJeMABHNoOoaoiJMRGE/Qm40WYv3GqOjRcE1+qnEdotCYfX1iOZTldej6LOrLpYdTeFq2+ax/tWbL9a27OgDUznMlPfXuuzDESii6V/MG038unbtmt9fvO+a9quiz73cf2Z+w1GXA3yEzOrb9dprr83NLsuvHU0Po89PrF/0h4tmpDWdvJifWG7//v1zH6votxhBL5osLqwIJOV9J4Ju9EmKYzS24fyU+3VF07yy+DuaM5b37/gsIrxH0In9Opo1xraI16irCP2xfvG+43sj9tWiUL8gQai+YQtYcIYjBwqDUwy4UO4wXVfVC5K1qekM/vymVx/0oS5i8IPodxOFn+irELUKERauv/76eTrMh5oKN/VdRmXxnCjQRq1M1HJE4TT63YwZMyYHjgXRkNunJhEcIuRdcsklNT5eDgWxraKGImqgojYx+tFEITRqpuK91raeZVHIjUJ1besQop9bFPJrErVyldWltmlB1bbshdmHo89S7EMxAEPUvJYv0BsBtKbw2RCfe3m5v/zlL3NYqEnUopVri8rX1orPM54TgSICUAyqUVdRwxQ1dhE84nkNMcJhDI5R274zPxGKoqYx3lMcy9GPLvrkRT+vyuIzidrOuFjyww8/nPvARZ/C6B8WfR2LxHFfDnGxnDieDj/88DRp0qT5Xq4g+jpFX7zYzrGeRSJsxTESYaty3zug4QlOQKHo+B4/ynEtnMrN6moSI5hFwSzOaseZ+7IonMRZ9PIIZw0lXivOgJfPFIe4jksoD+oQZ36jligKP5WvGxMF1rpa2GVEDVXUksQtRiiMQlWcvY/gVN4mcf2nmpojReErCokLq/w68dmUm9yVm4jFoAjRVK4sRt2LQQii6VZRCI5CYMwXtwhaUQCNwl+EqQUp2FauqYgmolFDsTDLqW3Z0WSqtm0e76l6jdGiEE3EIhTGoBqVh1Gv6UKpdRGfW4gTHdVrfavPEydF6rJd4yRBDIwRt6g1iUFf4kLC9QlOMfpfDEoSIxZWrulpLFFTeuONN+aBOGKgiwielQc9qbytoplx3OK4iaAZn9Vvf/vber1eBNEYhCOO/6iRnd/AGPGaEYRilL/KTT2Lap1inSJsAYuOpnpAoRhxLAruUciPAFRd1KbEaGchRhAL1Uc8K9dcRB+EhhYj1ZVFASjuR21QFOTLZ+mj8B8F8LJoxhdnkutqYZYR/UiqF6KiUFse1jsKplEgi4Jc5QJzFH7jLH95my6sGPI9AkPUdEUfsMqjsFUvqEdNQwwDHiN2VRfNy8pNB2PkturKtRjVhy2vr9jmMbJZhNaaajxrG3K6rsveY489ci1g5SadsX+XL9habqa6KMV6VK8tir46lfez+oj3FGEzakaqX3+s/Dox8mQUzmPExAjxtW3XWIfqzQVjOPKoga7vZxv7fDRrjZMFUfvS2CIwxsmMCHFxi2aIlZtiRjPO6tsvtlls2wXdr6O2KZp11iXcRBCKExrRPLAuKoet+jQnBOpHjRNQpx/lKEzGGdmoRYohcKMPRRS+o19KdOgvX7coai3iDHrUUEVhPAZaiOGNIxREs5MYkrshRS1QNA+L14yzs9EnIZqMxTVOIiSUw1oEt+jbEE2G4qz56NGjc3ip3NdofhZmGTHQRAwvHQXWKKzFIA1R01B5UItoAhVn8KNGL4bajnASBehouhWFzYYQYfLnP/95PvMfNU7xeUZNU9SaVe/jFP0s4sx4DCQRNUfRjykK0lEbE9Oj5i2CWPTfiqZ6sX2iRiu2SzR/igJihI+FFf024vXjs42mXrEtI6zFwAnRt6Wm4FZXsS3K16CK2pQYXj4KnlEwrmuBtSFqc6NZVnzO8d6iVjfeV3k49vqKsBfNQOMkR1y7KfbV6AcVtYcRBuI4jNq0aC4a+1sMvx21IHHdqwjKsa1jGTHMefRrjM8x+iPFcR3hJ9YthlCvXENWV7U1t6xJHCPx+VQXx1FD7FdxLBx00EH5ul9xEiBCZGVRax0nXuIEQnwusW9E074I1gs6jHq8ZlzvLvo4xndWfJcUBaH4vOqq3MQvalGX1guSQ6Orw8h7ANk///nP0pAhQ0o9e/bMwzjHEMPbb7996Yorrih9+eWXFVvpq6++Kp1zzjl5aOPWrVuXevToURo2bFiVeWobiri24YhrGlI6hvzu2LFjHpI3hrXu0KFDqVu3bnk44Dlz5lR5/nXXXZeHYG7btm0exjiG9C0PG1z02vVdRvXhyH/+85+Xtt5661KXLl3ykMTx3PPOOy8PD17Zn/70p7w9Y55OnTrlYZVffvnlKvOUX6/68N/lIYpjOxW58sor82cT72PLLbcsPfHEE3kI48rDkYdYv1/84hd5aOOYd/nlly/17ds3f7YxTH147LHH8lD1q666at4n4v8Y7jn2lSK1ff7Vvf/++/kzif0o9qfu3buXdttttzyMellNwzYXDUceJk+enIflXnbZZfP+E8NkVx4ev/rwz9XVNvRzXfftGPY6hqDu2rVrXodYlxjOvPo+VNs6lN935WH6wx/+8IfSdtttV7Evxf73+9//vso8zz33XOmggw7Kw9jH5xuv+e1vfzt/piGGrD/llFPycPpxrMexFn/H/lNkftusaDvF82q7nXvuuQ025Pajjz6al9miRYvS1KlTqzwWw9/H5xTHarzvGJY9hni//fbbC5db2zEa4riJZVU+1mrbV15//fU81Pz8hiOvrnyJBsORw6LRIv5p7PAGsCCilitqbmpqbgQA0JD0cQIAACggOAEAABQQnAAAAJbk4BQjMcWwpDG0aQzzW5dhfceNG5evIRHXUYnRrGIYXaB5iuNf/yYAYKkPTjEEaAxxGkP61kUMmxtD3sZwxs8//3y+qncMuRrD4gIAACwqS8yoelHjFNdIiOu81Oa0007L12epfCHEuJ5CXCsmrokAAACQmvsFcOPCgHG178oGDBiQa55qExcyrHyV77lz5+YLJsbFBSOsAQAAzVOpVMoX/I6uQ3GB8KUmOL333nupW7duVabF/RkzZqQvvvgitW/ffp7njBo1Kp1zzjmLcS0BAICmZOrUqWn11VdfeoLTghg2bFg6+eSTK+5Pnz49rbHGGnnjdOrUqVHXDQAAaDxRAdOjR4+03HLLFc7bpIJT9+7d0/vvv19lWtyPAFRTbVOI0ffiVl08R3ACAABa1KELT5O6jlO/fv3SY489VmXao48+mqcDAAAsKo0anOL6KzGseNzKw43H31OmTKloZjdw4MCK+Y877rj01ltvpVNPPTW9+uqr6corr0y33357OumkkxrtPQAAAEu/Rg1Of/vb39Lmm2+ebyH6IsXfw4cPz/enTZtWEaJCr1698nDkUcsU13+6+OKL07XXXptH1gMAAFjqr+O0ODuAde7cOQ8SoY8TAABNyZw5c9JXX33V2KvRpLRp06bWocbrkw2a1OAQAADQHEVdR1ya55NPPmnsVWlyIjRFy7UIUAtDcAIAgCVcOTStvPLKqUOHDnUaBY6U5s6dm/7zn//kLkBxSaKF2W6CEwAALOHN88qhacUVV2zs1WlyVlpppRyevv7669S6desFXk6TGo4cAACam3Kfpqhpov7KTfQigC4MwQkAAJoAzfMad7sJTgAAQIN78cUX04UXXrjQNT1LCsEJAABYKOPGjcs1O5VH/dt4443ThAkT0llnnVXjc3r27Jkuu+yyJrPlBScAAFjKHXnkkTnYHHfccfM8dsIJJ+THYp6GHgb8lltuSU8++WR64IEHUlMnOAEAQDPQo0ePdOutt6YvvviiYtqXX36Zw00M1b0otG/fPgenffbZJzV1ghMAADQDW2yxRQ5Pd999d8W0+DtC0+abb14xbdasWenEE0/Mw5+3a9cu7bDDDumvf/1rlWU9+OCDab311svBaJdddknvvPPOPK/31FNPpR133DHPs/rqq+earU8//bTW9Ytmfsccc0wePrxTp05p1113TS+88EJaUghOAADQTBx11FHp+uuvr7g/duzYNHjw4CrznHrqqemuu+5KN954Y5o8eXJaZ5110oABA9L//ve//PjUqVPTQQcdlPbbb7/0/PPP57Bz+umnV1nGm2++mfbaa690yCGH5EEi7rjjjjRx4sT0/e9/v9Z1i3k/+OCD9Mc//jFNmjQpB73ddtut4nUbm+AEAADNxBFHHJFrgt599918e/rpp/O0spkzZ6bf/OY36Ze//GUOPhtttFG65pprcq3Rddddl+eJx9dee+108cUXp/XXXz8dfvjh8/SPGjVqVPre976Xa64iePXr1y9dfvnlualgvEZ1sU4RrCJgbbnllmnddddNF110UerSpUu6884705KgVWOvAAAAsHhEM7job3TDDTekUqmU/+7atWuVmqK44O72229fMa1169Zp6623Tq+88kq+H/9vs802VZYbwaiyaGL3t7/9LYes6t5+++20ySabzDP/Z599llZcccUq06M/VqzTkkBwAgCAZtZcb+jQofnv0aNHL5LX+Oyzz9Lw4cPTOeecU+f5V1lllTyseXVR67Qk0FQPAACakT333DPNnj071yxF36XKoglemzZtchO+spjvr3/9a262FzbccMPcrK6yZ555psr96J/05z//uc7rFPO/9957qVWrVrlpX+Vb5RqxxiQ4AQBAM9KyZcvc3O7ll1/Of1fWsWPHdPzxx6dTTjklPfTQQ3meIUOGpM8//zwdffTReZ64FtTrr7+e53nttdfycObR9K+y0047LQ/wcOyxx6bnnnsuz3/vvffmZdWkf//+ubnfAQcckB555JE8St/48ePTmWeemZv8LQkEJwAAaGZiuO+41eSCCy5IBx98cB7cIWqC3njjjfTwww+n5ZdfPj8ew5fHqHsRhHr37p3GjBmTzj///CrL2GyzzdLjjz+eA9BOO+2UhzsfMWJE6tWrV42vGRfgjSHOY94Y5S+GOj/ssMPyABbdunVLS4IWpegV1ozMmDEjde7cOU2fPr3WnQUAAJYUcZHaGFAhQkdcV4mG2371yQZqnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABVoVzQAAACyZ+p5y02J7rUm/HFjv5xx55JHpxhtvTN///vfTmDFjqjx2wgknpCuvvDINGjQo3XDDDXneTz75JN177701Lqtnz57p3XffzX936NAhrb/++mnYsGHpkEMOSYuDGicAAGCR6dGjR7r11lvTF198UTHtyy+/TLfccktaY4016rWskSNHpmnTpqXnnnsubbXVVunQQw9N48ePT4uD4AQAACwyW2yxRQ5Pd999d8W0+DtC0+abb16vZS233HKpe/fuab311kujR49O7du3T/fdd19aHAQnAABgkTrqqKPS9ddfX3F/7NixafDgwQu1zFatWqXWrVun2bNnp8VBcAIAABapI444Ij311FO5j1Lcnn766TxtQUVYGjVqVJo+fXradddd0+JgcAgAAGCRWmmlldI+++yTB4EolUr5765du9Z7Oaeddlr62c9+lvtILbvssumCCy7Iy1ocBCcAAGCxNNcbOnRo/jv6Jy2IU045JY++F6GpW7duqUWLFmlxEZwAAIBFbs8998xN7CLsDBgwYIGWEbVU66yzTmoMghMAALDItWzZMr3yyisVf9ck+iw9//zzVaatuOKKeVS+xiY4AQAAi0WnTp3m+/i4cePmGaL86KOPTtdee21qbC1K0TurGZkxY0bq3LlzTrNFHxwAADS2GAjh7bffTr169Urt2rVr7NVZqrZffbKB4cgBAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAVaFc0AAAAsmaaM3HSxvdYaw1+s93OOPPLIdOONN+a/W7VqlVZfffV0yCGHpJEjR6Z27drl6S1atEht27ZNr732WlpzzTUrnnvAAQekLl26pBtuuKHKskaNGpVOP/30ivnuvffedOCBB6ZSqZQWJTVOAADAIrPnnnumadOmpbfeeitdeuml6aqrrkojRoyoMk+Ep+HDhxcuK8LWL37xi/Txxx8v9k9McAIAABaZtm3bpu7du6cePXrkWqT+/funRx99tMo8Q4cOTb/97W/TSy+9NN9lxXNjWVHrtLgJTgAAwGLx0ksvpfHjx6c2bdpUmb799tunfffdt0oTvJq0bNkynX/++emKK65I//rXv9LiJDgBAACLzP3335+WXXbZ3Mxu0003TR988EE65ZRT5pkvapEeeuih9OSTT853edGfqU+fPvM091vUBCcAAGCR2WWXXdLzzz+fnn322TRo0KA0ePDgdPDBB88z30YbbZQGDhxYWOsUop9TDBTxyiuvpMVFcAIAABaZjh07pnXWWSf17t07jR07Ngeo6667rsZ5zznnnDR58uQ8Ut787LTTTmnAgAFp2LBhaXERnAAAgMUTPpZZJp1xxhnpZz/7Wfriiy/meTwGkIiBImKeOXPmzHdZF1xwQbrvvvvShAkT0uIgOAEAAIvNIYcckgd5GD16dI2PRy3Sf/7zn/SnP/1pvsuJ/lKHH354+tWvfpUWB8EJAABYbFq1apVrlS688MI0c+bMeR5fYYUV0mmnnZa+/PLLwmXFhXTnzp2bFocWpUV9id0lzIwZM1Lnzp3T9OnTU6dOnRp7dQAAYL4iQLz99tupV69eeWQ6Gm771ScbqHECAAAoIDgBAAAUaFU0AwCLxpSRm9q09bTG8BdtMwAaheAELLS+p9xkKy6Ae5az2QCgqdBUDwAAmoBmNqbbErfdBCcAAFiCtW7dOv//+eefN/aqNEmzZ8/O/8e1oxaGpnoAALAEiwJ/ly5d0gcffJDvd+jQIbVo0aKxV6tJiGs8ffjhh3mbxfWjFobgBAAAS7ju3bvn/8vhibpbZpll0hprrLHQYVNwAgCAJVwU+ldZZZW08sorp6+++qqxV6dJadOmTQ5PC0twAgCAJtRsb2H76rBgDA4BAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAACzpwWn06NGpZ8+eqV27dmmbbbZJEydOrHXer776Ko0cOTKtvfbaef7evXunhx56aLGuLwAA0Pw0anC67bbb0sknn5xGjBiRJk+enIPQgAED0gcffFDj/D/72c/SVVddla644or08ssvp+OOOy4deOCB6bnnnlvs6w4AADQfjRqcLrnkkjRkyJA0ePDgtNFGG6UxY8akDh06pLFjx9Y4/80335zOOOOMtPfee6e11lorHX/88fnviy++eLGvOwAA0Hw0WnCaPXt2mjRpUurfv///X5lllsn3J0yYUONzZs2alZvoVda+ffv01FNPLfL1BQAAmq9GC04fffRRmjNnTurWrVuV6XH/vffeq/E50Ywvaqlef/31NHfu3PToo4+mu+++O02bNq3W14mwNWPGjCo3AACAJjU4RH1cfvnlad11100bbLBBatOmTRo6dGhu5hc1VbUZNWpU6ty5c8WtR48ei3WdAQCApq/RglPXrl1Ty5Yt0/vvv19letzv3r17jc9ZaaWV0r333ptmzpyZ3n333fTqq6+mZZddNvd3qs2wYcPS9OnTK25Tp05t8PcCAAAs3RotOEWNUd++fdNjjz1WMS2a38X9fv36zfe50c9ptdVWS19//XW666670v7771/rvG3btk2dOnWqcgMAAKiPVqkRxVDkgwYNSltuuWXaeuut02WXXZZrk6L5XRg4cGAOSNHcLjz77LPp3//+d+rTp0/+/+yzz85h69RTT23MtwEAACzlGjU4HXrooenDDz9Mw4cPzwNCRCCKC9qWB4yYMmVKlf5LX375Zb6W01tvvZWb6MVQ5DFEeZcuXRrxXQAAAEu7FqVSqZSakRhVLwaJiP5Omu1Bw+h7yk025QK4Z7lf2m71tMbwF20zABolGzSpUfUAAACaXVM9AABozqaM3LSxV6FJWqMRWiCocQIAACigxgkAgAahz2v93bOcna+pUOMEAABQQHACAAAoIDgBAAAU0MeJRmEEmQXjGjYAAI1DjRMAAEABwQkAAKCApnoNwNCb9WfoTQAAmhI1TgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAECBVkUzAAAsKlNGbmrj1tMaw1+0zaARqHECAAAoIDgBAAAUEJwAAAAK6OMEAA2g7yk32Y4L4J7lbDagaVDjBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAwJIenEaPHp169uyZ2rVrl7bZZps0ceLE+c5/2WWXpfXXXz+1b98+9ejRI5100knpyy+/XGzrCwAAND+NGpxuu+22dPLJJ6cRI0akyZMnp969e6cBAwakDz74oMb5b7nllnT66afn+V955ZV03XXX5WWcccYZi33dAQCA5qNRg9Mll1yShgwZkgYPHpw22mijNGbMmNShQ4c0duzYGucfP3582n777dN3v/vdXEu1xx57pO985zuFtVQAAABNMjjNnj07TZo0KfXv3///r8wyy+T7EyZMqPE52223XX5OOSi99dZb6cEHH0x77713ra8za9asNGPGjCo3AACA+miVGslHH32U5syZk7p161Zletx/9dVXa3xO1DTF83bYYYdUKpXS119/nY477rj5NtUbNWpUOueccxp8/QEAgOaj0QeHqI9x48al888/P1155ZW5T9Tdd9+dHnjggXTuuefW+pxhw4al6dOnV9ymTp26WNcZAABo+hqtxqlr166pZcuW6f33368yPe537969xuecddZZ6Xvf+1465phj8v1NN900zZw5Mx177LHpzDPPzE39qmvbtm2+AQAANLkapzZt2qS+ffumxx57rGLa3Llz8/1+/frV+JzPP/98nnAU4StE0z0AAIClqsYpxFDkgwYNSltuuWXaeuut8zWaogYpRtkLAwcOTKuttlrupxT222+/PBLf5ptvnq/59MYbb+RaqJheDlAAAABLVXA69NBD04cffpiGDx+e3nvvvdSnT5/00EMPVQwYMWXKlCo1TD/72c9SixYt8v///ve/00orrZRD03nnndeI7wIAAFjaNWpwCkOHDs232gaDqKxVq1b54rdxAwAAWFya1Kh6AAAAjUFwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAABCcAAAAFo4aJwAAgAKCEwAAQAHBCQAAYFEGp9mzZ6fXXnstff311wuzGAAAgKUvOH3++efp6KOPTh06dEgbb7xxmjJlSp7+wx/+MF1wwQUNvY4AAABNLzgNGzYsvfDCC2ncuHGpXbt2FdP79++fbrvttoZcPwAAgEbXakGedO+99+aAtO2226YWLVpUTI/apzfffLMh1w8AAKBp1jh9+OGHaeWVV55n+syZM6sEKQAAgGYbnLbccsv0wAMPVNwvh6Vrr7029evXr+HWDgAAoKk21Tv//PPTXnvtlV5++eU8ot7ll1+e/x4/fnx6/PHHG34tAQAAmlqN0w477JAHh4jQtOmmm6ZHHnkkN92bMGFC6tu3b8OvJQAAQFOqcfrqq6/S97///XTWWWela665ZtGsFQAAQFOucWrdunW66667Fs3aAAAALC1N9Q444IA8JDkAAEBzsECDQ6y77rpp5MiR6emnn859mjp27Fjl8RNPPLGh1g8AAKBpBqfrrrsudenSJU2aNCnfKouhyQUnAAAgNffg9Pbbbzf8mgAAACxNfZwqK5VK+QYAALC0WuDgdNNNN+VrOLVv3z7fNttss3TzzTc37NoBAAA01aZ6l1xySb6O09ChQ9P222+fpz311FPpuOOOSx999FE66aSTGno9AQAAmlZwuuKKK9JvfvObNHDgwIpp3/zmN9PGG2+czj77bMEJAABYqixQU71p06al7bbbbp7pMS0eAwAASM09OK2zzjrp9ttvn2f6bbfdlq/xBAAAkJp7U71zzjknHXrooemJJ56o6OMUF8N97LHHagxUAAAAza7G6eCDD07PPvts6tq1a7r33nvzLf6eOHFiOvDAAxt+LQEAAJpajVPo27dv+u1vf9uwawMAALC01Dg9+OCD6eGHH55nekz74x//2BDrBQAA0LSD0+mnn57mzJkzz/RSqZQfAwAAWJosUHB6/fXX00YbbTTP9A022CC98cYbDbFeAAAATTs4de7cOb311lvzTI/Q1LFjx4ZYLwAAgKYdnPbff//04x//OL355ptVQtNPfvKT9M1vfrMh1w8AAKBpBqcLL7ww1yxF07xevXrlW/y94oorposuuqjh1xIAAKCpDUceTfXGjx+fHn300fTCCy+k9u3bp969e6cdd9yx4dcQAACgKdU4TZgwId1///357xYtWqQ99tgjrbzyyrmWKS6Ke+yxx6ZZs2YtqnUFAABY8oPTyJEj0z/+8Y+K+y+++GIaMmRI2n333fMw5Pfdd18aNWrUolhPAACAphGcnn/++bTbbrtV3L/11lvT1ltvna655pp08sknp1/96lfp9ttvXxTrCQAA0DSC08cff5y6detWcf/xxx9Pe+21V8X9rbbaKk2dOrVh1xAAAKApBacITW+//Xb+e/bs2Wny5Mlp2223rXj8008/Ta1bt274tQQAAGgqwWnvvffOfZmefPLJNGzYsNShQ4cqI+n9/e9/T2uvvfaiWE8AAICmMRz5ueeemw466KC08847p2WXXTbdeOONqU2bNhWPjx07No+0BwAA0GyDU9euXdMTTzyRpk+fnoNTy5Ytqzx+xx135OkAAABLkwW+AG5NVlhhhYVdHwAAgKbdxwkAAKA5EpwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAphCcRo8enXr27JnatWuXttlmmzRx4sRa5/3GN76RWrRoMc9tn332WazrDAAANB+NHpxuu+22dPLJJ6cRI0akyZMnp969e6cBAwakDz74oMb577777jRt2rSK20svvZRatmyZDjnkkMW+7gAAQPPQ6MHpkksuSUOGDEmDBw9OG220URozZkzq0KFDGjt2bI3zr7DCCql79+4Vt0cffTTPLzgBAABLZXCaPXt2mjRpUurfv///X6Fllsn3J0yYUKdlXHfddemwww5LHTt2rPHxWbNmpRkzZlS5AQAANJng9NFHH6U5c+akbt26VZke9997773C50dfqGiqd8wxx9Q6z6hRo1Lnzp0rbj169GiQdQcAAJqPRm+qtzCitmnTTTdNW2+9da3zDBs2LE2fPr3iNnXq1MW6jgAAQNPXqjFfvGvXrnlgh/fff7/K9Lgf/ZfmZ+bMmenWW29NI0eOnO98bdu2zTcAAIAmWePUpk2b1Ldv3/TYY49VTJs7d26+369fv/k+94477sj9l4444ojFsKYAAEBz1qg1TiGGIh80aFDacsstc5O7yy67LNcmxSh7YeDAgWm11VbLfZWqN9M74IAD0oorrthIaw4AADQXjR6cDj300PThhx+m4cOH5wEh+vTpkx566KGKASOmTJmSR9qr7LXXXktPPfVUeuSRRxpprQEAgOak0YNTGDp0aL7VZNy4cfNMW3/99VOpVFoMawYAANDER9UDAABYHAQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAABLenAaPXp06tmzZ2rXrl3aZptt0sSJE+c7/yeffJJOOOGEtMoqq6S2bdum9dZbLz344IOLbX0BAIDmp1Vjvvhtt92WTj755DRmzJgcmi677LI0YMCA9Nprr6WVV155nvlnz56ddt999/zYnXfemVZbbbX07rvvpi5dujTK+gMAAM1DowanSy65JA0ZMiQNHjw4348A9cADD6SxY8em008/fZ75Y/r//ve/NH78+NS6des8LWqrAAAAlsqmelF7NGnSpNS/f///vzLLLJPvT5gwocbn/OEPf0j9+vXLTfW6deuWNtlkk3T++eenOXPmLMY1BwAAmptGq3H66KOPcuCJAFRZ3H/11VdrfM5bb72V/vznP6fDDz8892t644030g9+8IP01VdfpREjRtT4nFmzZuVb2YwZMxr4nQAAAEu7Rh8coj7mzp2b+zddffXVqW/fvunQQw9NZ555Zm7iV5tRo0alzp07V9x69OixWNcZAABo+hotOHXt2jW1bNkyvf/++1Wmx/3u3bvX+JwYSS9G0YvnlW244Ybpvffey03/ajJs2LA0ffr0itvUqVMb+J0AAABLu0YLTm3atMm1Ro899liVGqW4H/2YarL99tvn5nkxX9k///nPHKhieTWJIcs7depU5QYAANBkmurFUOTXXHNNuvHGG9Mrr7ySjj/++DRz5syKUfYGDhyYa4zK4vEYVe9HP/pRDkwxAl8MDhGDRQAAACyVw5FHH6UPP/wwDR8+PDe369OnT3rooYcqBoyYMmVKHmmvLPonPfzww+mkk05Km222Wb6OU4So0047rRHfBQAAsLRr1OAUhg4dmm81GTdu3DzTohnfM888sxjWDAAAoAmOqgcAANAYBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAKCA4AQAAFBAcAIAACggOAEAABQQnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoIDgBAAAUEBwAgAAKCA4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAAAUEJwAAAAKCE4AAAAFBCcAAIACghMAAEABwQkAAEBwAgAAWDhqnAAAAAoITgAAAAUEJwAAgAKCEwAAQAHBCQAAoCkEp9GjR6eePXumdu3apW222SZNnDix1nlvuOGG1KJFiyq3eB4AAMBSG5xuu+22dPLJJ6cRI0akyZMnp969e6cBAwakDz74oNbndOrUKU2bNq3i9u677y7WdQYAAJqXRg9Ol1xySRoyZEgaPHhw2mijjdKYMWNShw4d0tixY2t9TtQyde/eveLWrVu3xbrOAABA89KqMV989uzZadKkSWnYsGEV05ZZZpnUv3//NGHChFqf99lnn6U111wzzZ07N22xxRbp/PPPTxtvvHGN886aNSvfyqZPn57/nzFjRoO9jzmzvmiwZTUXn7ae09ir0CQ15H7bkBwDC8ZxsPQcA8FxsGAcB/XnOFi6OAYa9zgoL6dUKi3Zwemjjz5Kc+bMmafGKO6/+uqrNT5n/fXXz7VRm222WQ5BF110Udpuu+3SP/7xj7T66qvPM/+oUaPSOeecM8/0Hj16NOA7ob42sckWzKjOttxSxHGwABwDSx3HwQJwHCxVHANLxnHw6aefps6dOy+5wWlB9OvXL9/KIjRtuOGG6aqrrkrnnnvuPPNHbVb0oSqLWqr//e9/acUVV8xN/lj8ItlHcJ06dWrurwbNkeMAHAfgt6DxRU1ThKZVV121cN5GDU5du3ZNLVu2TO+//36V6XE/+i7VRevWrdPmm2+e3njjjRofb9u2bb5V1qVLl4VYaxpKhCbBiebOcQCOA/Bb0LiKapqWiMEh2rRpk/r27Zsee+yxKjVCcb9yrdL8RFO/F198Ma2yyiqLcE0BAIDmrNGb6kUzukGDBqUtt9wybb311umyyy5LM2fOzKPshYEDB6bVVlst91UKI0eOTNtuu21aZ5110ieffJJ++ctf5uHIjznmmEZ+JwAAwNKq0YPToYcemj788MM0fPjw9N5776U+ffqkhx56qGLAiClTpuSR9so+/vjjPHx5zLv88svnGqvx48fnocxpGqLpZFy3q3oTSmhOHAfgOAC/BU1Li1Jdxt4DAABoxhr9ArgAAABLOsEJAACggOAEAABQQHACaARxAe577723weeF5qDyMfHOO+/k+88//3xjrxawlBOcyCZMmJAvRrzPPvvYIjQ7Rx55ZC54xS2uLxeXO4hLH3z99deL7DWnTZuW9tprrwafFxbn8RIXoe/Vq1c69dRT05dffmnjs1Tt35Vvb7zxRnriiSfSfvvtl1ZdddV6ndB64YUX0je/+c208sorp3bt2qWePXvmUaU/+OCDRf5+aFiCE9l1112XfvjDH+Yvhf/85z+NtlVmz57tE6FR7LnnnjmgvP766+knP/lJOvvss/N14hbVPtq9e/c6D8lfn3lhcR4vb731Vrr00kvTVVddlS8zAUvT/l35FicI4jqjvXv3TqNHj67zsuKSO7vttltaYYUV0sMPP5xeeeWVdP311+fwFctbVL766qtFtuzmTHAiffbZZ+m2225Lxx9/fK5xuuGGG6pslfvuuy9ttdVW+SxJ165d04EHHljx2KxZs9Jpp52WevTokQt2caY+QliI5XTp0qXKsuLsTJylKYvCaVy769prr81fSvEaIa7ltcMOO+Tnr7jiimnfffdNb775ZpVl/etf/0rf+c538pdRx44d80WUn3322dxsI6799be//a3K/HFx5TXXXDPNnTvXp848Yv+NgBL7SBwL/fv3T3/4wx/y2ccDDjggnXfeefmHbv3118/zT506NX3729/O+2jsg/vvv3/e9yobO3Zs2njjjfOyV1lllTR06NCKxyqfrYwwFo/FPHEMxDqUL/pdfd7w4osvpl133TW1b98+Hx/HHntsPo7Lyut80UUX5WXGPCeccIIfUhr8eInv/tjX4nh59NFH82PxHRv7b3ynxz4aBc0777yzyvP/8Y9/5O/1Tp06peWWWy7tuOOOFd/xf/3rX9Puu++ef286d+6cdt555zR58mSfHot9/658i1Y5UfP/85//vEo5qMjTTz+dpk+fnss5m2++eT4udtlll3zCIf6uyzERx1S0glh99dXzupWveVpWbq4aZbk4XuJ35He/+11+LF53ww03zNM22GCDdOWVVzbotmpuBCfS7bffng+mKBAeccQRubBXvrzXAw88kL8g9t577/Tcc8+lxx57LG299dYVW23gwIHp97//ffrVr36Vz6LEWcdll122Xls1qr/vuuuudPfdd1e0UY+zMCeffHIOP/GaEYRiPcqhJwqJ8eXw73//Oxduoxo8morE41EFHj/icUansrgfBcrKF1SG2kSBr1y7FPvga6+9lguG999/fw4gAwYMyD9uTz75ZP5hjP0+zlKWn/Ob3/wmh5UINRF0Yj+NEws1ieMnHo9jMV4nfvBiP65JHBvx2nEB8Chg3nHHHelPf/pTlVAW/vKXv+Qf3fj/xhtvzCcyqp8UgYbw0ksv5QvRRzPXEKHppptuSmPGjMmFwZNOOin/tjz++OP58fje3mmnnXIB8M9//nOaNGlSOuqooyqaxn766adp0KBB6amnnkrPPPNMWnfddfNvUEyHpiZCV+zb99xzT0XZqrqiY+Lyyy9PF198cT4Z9ve//z3/BkTTv2ghUdnpp5+efvSjH+XyWMwTvyXDhw/PJ/5i2vnnn5/OOuus/JvAAooL4NK8bbfddqXLLrss//3VV1+VunbtWvrLX/6S7/fr1690+OGH1/i81157Lb4BSo8++miNj19//fWlzp07V5l2zz335OeUjRgxotS6devSBx98MN91/PDDD/PzXnzxxXz/qquuKi233HKl//73vzXOf9ttt5WWX3750pdffpnvT5o0qdSiRYvS22+/Pd/XoXkaNGhQaf/9989/z507N+/Tbdu2Lf30pz/Nj3Xr1q00a9asivlvvvnm0vrrr5/nLYvH27dvX3r44Yfz/VVXXbV05pln1vqasT/H8RB++MMflnbdddcqy6tt3quvvjrv25999lnF4w888EBpmWWWKb333nsV72fNNdcsff311xXzHHLIIaVDDz10gbcRlMX+1bJly1LHjh3zcRL7Z+x/d955Z/7O7dChQ2n8+PFVNtjRRx9d+s53vpP/HjZsWKlXr16l2bNn12mjzpkzJ3/f33fffTUeE/G9Hvefe+45HxINun+Xb9/61rfmma/yPljkjDPOKLVq1aq0wgorlPbcc8/ShRdeWPF9XZdjIn5PzjvvvCrTttpqq9IPfvCDKsdAuSxXtvbaa5duueWWKtPOPffcXLZjwTj13szF2e2JEyfmJm+hVatWucNiubld1ABF29yaxGNRdR01PwsjmiWttNJKVabFWZRYp7XWWitXW5fPvk+ZMqXitaPKO5pI1SSajsS6xRmeEGfao2q8trP4EDVJUWsUzRmiOUYcB9GUNGy66aYVZ9ND1HBGTWnUOMVz4hb7YnSOj1qe6PAbfQVrO3aqi5rQ2Kej1vfEE09MjzzySK3zxlnDaPoUzVPLtt9++1zbGsdzWTQRjGOgLJrs6YhMQ4nv09hno3l01A4NHjw4HXzwwfm4+Pzzz3NTu/KxEbeogSo3O4rnRTOkGFiiJu+//34aMmRIrmmKpnrxGxCtDMrf/7C49u/yLVoF1EXU6FTe78v7bNT4vPfee7kWNr6b4/9o6ROtEYqOiRkzZuTfk/ieryzux+9BZdFloXLrhDjmjj766CrrFE0Nq3d9oO5a1WNelkIRkKIqOPpulMWJlKgu/vWvf52bK9Vmfo+FaBJXvVq6ps6KlQuAZTFqTQSqa665Jq9bFAo32WSTimZQRa8dhdxoRhjN8w466KB0yy235KpumN8PZTSvi30n9rk4iVDbPhqFuL59+1a0Ia8sTgLUtznoFltskd5+++30xz/+MTe7i75T0dy0er+Q+qj+Axzt3/Xvo6HEMVFuehrNuyPMx+9JfE+Xm3mvttpqVZ5THuCk6Ps7gth///vf/J0dvwPxvH79+hk8iEbZv+vjuOOOy9/fZZXLVtHX9JBDDsm3CFhx8jea3kWzuaJjoj7rXVbu9xrlqG222abKfJVPqlE/glMzFoEpzgJGu9k99thjnhqb6Lu02Wab5f4dcTaxujgLHwWxaLcehbyaCpDRJj3OepQP5rpcZyN+MOPMeRzscQYmRFv3ymK9osPj//73v1prnY455pj8Ix4dIeO9RoCChvihjKATnXBjaNk4G16TqN2MYycCWV3EcqKWK27f+ta3cn+pmvbv6OQbNaiVj6voYxVhrTxwBSxOse+dccYZuV/qP//5zxx04kx7ba0R4vs7CotxIq2mM+yxP8f3dvRrKg/E8tFHHy3y9wELK76vayuTVBYn6NZee+2KUfXmd0zEb0MEsDguKh9Tcb9yn/PqunXrlp8XI18efvjhC/W++P801WvmTZM+/vjjXI0bAaPyLZpcxNnDGF42AlT8H1XCUa38i1/8oqJgGGcGowNjjPgVZ8zHjRuXO7iHOMPRoUOH/IMa1cJR61OXzunR6T3OzFx99dW52Ud0lIwf5MqiGV90uIyAF18e8cUQA0zE9agqFzC33XbbPOpfzN9QZ3QgfoRixK8YSS8Ghyjv+9HMLkZ7DNHML05KRBOPaHoao4JdccUVNW68Sy65JB9nr776ai54xoAPsX9XH5Wy/NrRnDCOveiUH4M/xKUEvve97+UfSmgMcRY9zmLHAEE//elP84AQURCM7/7yvl/ukB4DmUTzo8MOOywPABTHx80331zR1DSa6MX9+M2JpoCxz/v+ZkkQtTjl5nshvvvj7/k1I42yVgyOEv/H93vs51HT9OCDD+bfkLocE6ecckoue8UJu5gWg0DE68ZAEPNzzjnn5MFa4ncoXjvKcNESJ35zWEAL2DeKpcC+++5b2nvvvWt87Nlnn80dDV944YXSXXfdVerTp0+pTZs2eeCIgw46qGK+L774onTSSSeVVllllfz4OuusUxo7dmzF49FxMqZFp/l4vejYXn1wiN69e8/z+tE5f8MNN8wdjzfbbLPSuHHj5umI+c4775QOPvjgUqdOnXJn5C233DKvd2XXXXddft7EiRMXenvRPAaHqOtj06ZNKw0cODAfE7GfrrXWWqUhQ4aUpk+fXjHPmDFj8iASMQBKHCMxCERtAz7EMRadkGN/3m233UqTJ0+ucd7w97//vbTLLruU2rVrlzsbx+t++umn813nH/3oR6Wdd955gbcRFB0To0aNKq200kp54JLopF7e92PagAEDSo8//njFvPHbsscee+Tv7hj4Yccddyy9+eab+bHY9+P7PPbvddddt3THHXfkwU4uvfTSGo8Jg0OwuH4PYuCs2Peq3+I5tYn9Or6j11tvvVwW6tKlSx7YIQbQqmx+x0QMkHL22WeXVltttXxMRbnpj3/8Y8Vz53cM/O53v6sow8XAQjvttFPp7rvvXogt1Ly1iH8WNHTBku7cc8/NZ+9j+E4AAFhQmuqx1FanRzOmGOAimjEBAMDCEJxYKkV74Rj17Bvf+EbugwUAAAtDUz0AAIACapwAAAAKCE4AAAAFBCcAAIACghMAAEABwQmAJu3yyy9PEyZMaOzVAGApJzgB0GRdfPHF6e67705bbLHFAi+jRYsW6d57723Q9QJg6SM4AdDojjzyyBxgjjvuuHkeO+GEE/JjMU9lTz/9dLr55pvT//3f/6W2bdtWTB83blye/5NPPqnTa0+bNi3ttddeDfAuAFiaCU4ALBF69OiRbr311vTFF19UTPvyyy/TLbfcktZYY4155t9+++3T888/n7p06bJArzd79uz8f/fu3asELwCoieAEwBIhmttFeIqmd2Xxd4SmzTffvGLa3Llz06hRo1KvXr1S+/btU+/evdOdd96ZH3vnnXfSLrvskv9efvnlq9RUfeMb30hDhw5NP/7xj1PXrl3TgAEDamyqN3HixPx67dq1S1tuuWW655578jwR0sINN9wwT1iL58c8lUVNWLynWM5aa62VzjnnnPT1118vgi0HwOLQarG8CgDUwVFHHZWuv/76dPjhh+f7Y8eOTYMHD87N78oiNP32t79NY8aMSeuuu2564okn0hFHHJFWWmmltMMOO6S77rorHXzwwem1115LnTp1yuGq7MYbb0zHH398buZXk88++yztu+++affdd8+v8fbbb6cf/ehH9f7snnzyyTRw4MD0q1/9Ku24447pzTffTMcee2x+bMSIEfYFgCZIcAJgiREBaNiwYendd9/N9yPgRPO9cnCaNWtWOv/889Of/vSn1K9fvzwtanOeeuqpdNVVV6Wdd945rbDCCnn6yiuvPE/NUAStCy+8sNbXj2aBUaN13XXX5ZqijTfeOP3rX//KYas+onbp9NNPT4MGDapYx3PPPTedeuqpghNAEyU4AbDEiFqjffbZJzeHK5VK+e9oVlf2xhtvpM8//zzXCFXvr1S5OV9t+vbtO9/HX3nllbTZZpvl0FRWDmj18cILL+TQd95551VMmzNnTu6zFevfoUOHei8TgMYlOAGwxDXXi75IYfTo0fM0pQsPPPBAWm211ao8VpcBHjp27LjQ67fMMsvkUFfZV199Nc96Rq3TQQcdNM/zK4cyAJoOwQmAJcqee+6Za5BisIXyAA5lG220UQ5IU6ZMyc3yatKmTZuKGp762nDDDfMQ51EzVA44zzzzzDy1Yp9++mmaOXNmRRArDxxRFoNCRB+rddZZp97rAMCSSXACYInSsmXL3GSu/Hdlyy23XPrpT3+aTjrppNwXKQaDmD59em4WFwNBRJ+iNddcM4eu+++/P+299955cIhll122Tq/93e9+N5155plpyJAhua9VjNJ30UUXVZlnm222yU3tzjjjjHTiiSemZ599NjctrGz48OF5kIkYEfBb3/pWrqWK5nsvvfRS+vnPf77Q2wiAxc9w5AAscSIExa0mMcjCWWedlUfXixqiqKGKpnsxPHmIJnzlwRm6detW0eyvLiJg3XfffenFF1/MfaYiRP3iF7+oMk8MPhEj7j344INp0003Tb///e/T2WefXWWeqCmL4PbII4+krbbaKm277bbp0ksvzaEOgKapRal6Q20AoELUOkUoe+6551KfPn1sGYBmSo0TAABAAcEJAACggKZ6AAAABdQ4AQAAFBCcAAAACghOAAAABQQnAACAAoITAABAAcEJAACggOAEAABQQHACAAAoIDgBAACk+ft/GTU83jv3DUYAAAAASUVORK5CYII=",
                        "text/plain": [
                            "<Figure size 1000x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "metrics_df = pd.DataFrame({\n",
                "    'Modèle': ['MLP', 'RNN'],\n",
                "    'Accuracy': [mlp_metrics['accuracy'], rnn_metrics['accuracy']],\n",
                "    'Precision': [mlp_metrics['precision'], rnn_metrics['precision']],\n",
                "    'Recall': [mlp_metrics['recall'], rnn_metrics['recall']],\n",
                "    'F1-Score': [mlp_metrics['f1_score'], rnn_metrics['f1_score']]\n",
                "})\n",
                "\n",
                "metrics_df_melted = metrics_df.melt(id_vars='Modèle', var_name='Métrique', value_name='Score')\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x='Métrique', y='Score', hue='Modèle', data=metrics_df_melted)\n",
                "plt.title('Comparaison des Performances MLP vs RNN')\n",
                "plt.ylim(0.5, 1.0)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** Le graphique à barres montre que le MLP (en bleu) surpasse le RNN (en orange) sur toutes les métriques (Accuracy, Precision, Recall, F1-Score).\n",
                "\n",
                "* **Analyse Logique :** Cette visualisation confirme de manière claire et immédiate la supériorité du modèle MLP pour cette tâche spécifique. Le MLP est non seulement plus performant, mais aussi plus rapide à entraîner, ce qui en fait le meilleur choix dans ce contexte."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Partie 5 : Analyse et Amélioration**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **17. Analyser les résultats trouvés**\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "L'analyse des résultats de l'atelier révèle une conclusion contre-intuitive mais logique pour cette tâche spécifique de détection de spam : le **Perceptron Multicouche (MLP) surpasse le Réseau de Neurones Récurrent (RNN) simple** sur toutes les métriques d'évaluation (Accuracy, Précision, Rappel, F1-Score).\n",
                "\n",
                "#### **Analyse Comparative des Performances**\n",
                "\n",
                "| Modèle | Accuracy (Précision Globale) | Précision (Classe Spam) | Rappel (Classe Spam) | F1-Score |\n",
                "| --- | --- | --- | --- | --- |\n",
                "| **MLP** | **~89.3%** | **~94%** | ~86% | **~90%** |\n",
                "| **RNN** | ~83.4% | ~88% | ~81% | ~84% |\n",
                "\n",
                "1. **Supériorité du MLP :** Le MLP, utilisant une représentation **Bag-of-Words (BoW)**, s'est avéré plus efficace.\n",
                "  \n",
                "    - **Raison Logique :** La détection de spam sur YouTube est une tâche fortement basée sur la **présence de mots-clés** (ex: \"subscribe\", \"link\", \"check out my channel\"). Le modèle BoW capture parfaitement cette information de fréquence sans se soucier de l'ordre des mots.\n",
                "    - **Avantage Clé :** La **Précision** très élevée du MLP (~94%) est cruciale pour un filtre anti-spam, car elle minimise le risque de classer à tort un commentaire légitime (non-spam) comme spam.\n",
                "2. **Limitation du RNN Simple :** Le RNN simple, bien que conçu pour traiter les séquences, n'a pas réussi à exploiter l'ordre des mots pour surpasser le MLP.\n",
                "  \n",
                "    - **Raison Logique :** Le modèle **SimpleRNN** souffre du problème de la **disparition du gradient** (vanishing gradient), ce qui limite sa capacité à apprendre des dépendances à long terme. Pour des commentaires de longueur variable, il a du mal à maintenir le contexte sur toute la séquence.\n",
                "    - **Conclusion :** Pour cette tâche, l'information séquentielle n'apporte pas de valeur ajoutée significative par rapport à la simple fréquence des mots, et la faiblesse du SimpleRNN face aux dépendances longues le pénalise.\n",
                "\n",
                "#### **Analyse du Surapprentissage (Overfitting)**\n",
                "\n",
                "- **MLP :** La précision d'entraînement de **100%** contre une précision de test de **~89.3%** confirme un surapprentissage. Le modèle a mémorisé les données d'entraînement, mais il généralise très bien, ce qui est un bon signe pour un modèle simple.\n",
                "\n",
                "En conclusion, les résultats montrent que la **complexité n'est pas toujours synonyme de meilleure performance**. Pour la détection de spam, une approche simple et rapide (MLP + BoW) est plus performante qu'une approche séquentielle de base (SimpleRNN + Embedding). Pour améliorer le RNN, il faudrait passer à des architectures plus avancées comme LSTM ou GRU."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **18. Proposer des améliorations sur chaque modèl**e\n",
                "Propositions concrètes pour améliorer les performances des deux architectures."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### **Améliorations Proposées**\n",
                "\n",
                "**Pour le MLP :**\n",
                "1. **Vectorisation Avancée :** Utiliser **TF-IDF** (Term Frequency-Inverse Document Frequency) au lieu de `CountVectorizer` pour pondérer l'importance des mots. Les mots rares mais discriminants (comme les liens ou les noms de chaînes) auront plus de poids.\n",
                "2. **Hyperparamètres :** Optimiser le nombre de couches, le nombre de neurones par couche, et le taux d'apprentissage.\n",
                "3. **Régularisation :** Ajouter des couches de **Dropout** pour prévenir le surapprentissage.\n",
                "\n",
                "**Pour le RNN :**\n",
                "1. **Architecture :** Remplacer le `SimpleRNN` par des architectures plus robustes comme le **LSTM** (Long Short-Term Memory) ou le **GRU** (Gated Recurrent Unit). Ces architectures sont spécifiquement conçues pour atténuer le problème de la disparition du gradient et capturer des dépendances à long terme.\n",
                "2. **Taille de l'Embedding :** Augmenter la dimension de la couche d'embedding ou utiliser des embeddings pré-entraînés comme **Word2Vec** ou **GloVe**.\n",
                "3. **Bidirectionnalité :** Utiliser un RNN **Bidirectionnel** pour traiter la séquence dans les deux sens (avant et arrière), capturant ainsi un contexte plus riche."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **19. Montrer le cas de défaillance du RNN**\n",
                "Le cas de défaillance classique d'un RNN simple est lié à sa difficulté à gérer les dépendances à long terme (problème de la disparition du gradient). Nous allons simuler un exemple où l'information clé est éloignée de la décision."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Défaillance du RNN Simple (Dépendance à Long Terme) ---\n",
                        "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
                        "Commentaire 1 (Spam) : This is a very long and rambling comment about the...\n",
                        "Prédiction RNN : Spam\n",
                        "Commentaire 2 (Non-Spam) : This is a very long and rambling comment about the...\n",
                        "Prédiction RNN : Spam\n",
                        "\n",
                        "Note : Si le RNN simple prédit 'Non-Spam' pour le premier commentaire, cela illustre sa difficulté à capter le mot 'subscribe' ou 'check out my channel' qui arrive tard dans la séquence (dépendance à long terme). Un LSTM/GRU aurait plus de chances de réussir.\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n--- Défaillance du RNN Simple (Dépendance à Long Terme) ---\")\n",
                "\n",
                "# Exemple de commentaire où le mot clé est loin du début\n",
                "long_comment_spam = \"This is a very long and rambling comment about the video. It talks about the music, the quality, the lighting, and how much I enjoyed watching it. But wait, at the very end, I'm going to drop a link to my channel and ask you to subscribe. Check out my channel now!\"\n",
                "long_comment_non_spam = \"This is a very long and rambling comment about the video. It talks about the music, the quality, the lighting, and how much I enjoyed watching it. I really appreciate the effort you put into this video.\"\n",
                "\n",
                "# Prétraitement et vectorisation pour le RNN\n",
                "sequences_fail = tokenizer.texts_to_sequences([clean_text(long_comment_spam), clean_text(long_comment_non_spam)])\n",
                "X_fail = pad_sequences(sequences_fail, maxlen=MAX_LEN)\n",
                "\n",
                "# Prédiction\n",
                "y_pred_fail = (rnn_model.predict(X_fail) > 0.5).astype(\"int32\")\n",
                "\n",
                "print(f\"Commentaire 1 (Spam) : {long_comment_spam[:50]}...\")\n",
                "print(f\"Prédiction RNN : {'Spam' if y_pred_fail[0][0] == 1 else 'Non-Spam'}\")\n",
                "\n",
                "print(f\"Commentaire 2 (Non-Spam) : {long_comment_non_spam[:50]}...\")\n",
                "print(f\"Prédiction RNN : {'Spam' if y_pred_fail[1][0] == 1 else 'Non-Spam'}\")\n",
                "\n",
                "print(\"\\nNote : Si le RNN simple prédit 'Non-Spam' pour le premier commentaire, cela illustre sa difficulté à capter le mot 'subscribe' ou 'check out my channel' qui arrive tard dans la séquence (dépendance à long terme). Un LSTM/GRU aurait plus de chances de réussir.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* **Résultat :** Le RNN a classé les deux commentaires (le spam et le non-spam) comme Spam.\n",
                "\n",
                "* **Analyse Logique :** Le résultat obtenu est intéressant. Le RNN a correctement identifié le premier commentaire comme spam, ce qui signifie qu'il a réussi à capter les mots-clés de spam même s'ils étaient à la fin. Cependant, il a incorrectement classé le deuxième commentaire (non-spam) comme spam. Cela peut être dû au fait que les deux commentaires partagent une grande partie de leur texte, et le modèle a été confus. ce qui illustre sa **fragilité** et sa difficulté à différencier des commentaires structurellement similaires. Cela renforce l'idée que le SimpleRNN n'est pas l'architecture la plus robuste pour le NLP. Cela montre que le RNN simple peut être sensible à des variations mineures et ne pas toujours comprendre le contexte global de manière fiable. Un modèle plus avancé comme LSTM ou GRU pourrait mieux différencier ces deux cas. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Questions pour Discussion**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 1. L’application de différentes méthodes de vectorisation peut-elle influencer le résultat du modèle ?\n",
                "\n",
                "**Réponse Détaillée :**\n",
                "\n",
                "Oui, l'influence est **majeure**. La vectorisation est l'étape qui convertit le texte brut en une représentation numérique que le modèle peut traiter. Le choix de la méthode détermine la nature des informations textuelles capturées et transmises au modèle.\n",
                "\n",
                "| Méthode de Vectorisation | Information Capturée | Impact sur le Modèle |\n",
                "| :--- | :--- | :--- |\n",
                "| **Bag-of-Words (BoW) / CountVectorizer** | Fréquence des mots, présence/absence. | Bon pour les tâches basées sur les mots-clés (comme le spam). Ignore l'ordre et le contexte. |\n",
                "| **TF-IDF** | Importance relative des mots dans le corpus. | Améliore le BoW en donnant moins de poids aux mots très fréquents et non discriminants. Souvent plus performant que BoW. |\n",
                "| **Word Embeddings (Word2Vec, GloVe)** | Sémantique et relations contextuelles entre les mots. | Essentiel pour les tâches d'analyse de sentiments complexes. Nécessite des modèles comme le RNN/LSTM pour exploiter la séquence. |\n",
                "| **Tokenization + Padding (pour RNN)** | Séquence et ordre des mots. | Permet aux modèles séquentiels de capturer les dépendances et le contexte, crucial pour la compréhension du langage naturel.\n",
                "\n",
                "Un modèle comme le MLP est très sensible à la qualité de la vectorisation BoW/TF-IDF, tandis qu'un RNN dépend de la vectorisation séquentielle (Tokenization/Embedding) pour exploiter sa capacité à traiter l'ordre des mots."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 2. Dans quelles situations un MLP pourrait-il suffire pour traiter du texte ?\n",
                "\n",
                "**Réponse Détaillée :**\n",
                "\n",
                "Un Perceptron Multicouche (MLP) peut être suffisant, voire préférable, dans plusieurs situations, principalement lorsque la tâche ne dépend pas fortement de l'ordre séquentiel des mots :\n",
                "\n",
                "1. **Classification basée sur les mots-clés (comme la détection de spam) :** Comme démontré dans cet atelier, la présence de certains mots (ex: 'subscribe', 'link', 'free') est souvent le facteur le plus discriminant. Le MLP, combiné à BoW ou TF-IDF, est rapide et efficace dans ce cas.\n",
                "2. **Ensembles de données de petite taille :** Les modèles séquentiels (RNN/LSTM) nécessitent beaucoup de données pour apprendre des motifs complexes. Un MLP est plus simple et moins sujet au surapprentissage sur de petits corpus.\n",
                "3. **Contraintes de ressources :** L'entraînement et l'inférence d'un MLP sont beaucoup plus rapides et moins gourmands en ressources (CPU/GPU) que les RNN/LSTM, ce qui est un avantage dans les environnements à faible puissance.\n",
                "4. **Tâches de classification de documents :** Pour des documents longs où l'importance d'un mot est plus pertinente que sa position exacte, un MLP peut offrir une performance satisfaisante avec une complexité réduite."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 3. Quels avantages apporte un RNN par rapport à un MLP ?\n",
                "\n",
                "**Réponse Détaillée :**\n",
                "\n",
                "L'avantage fondamental d'un Réseau de Neurones Récurrent (RNN) sur un Perceptron Multicouche (MLP) réside dans sa capacité à traiter les **données séquentielles** et à maintenir une **mémoire** des entrées précédentes. Cela est crucial pour le traitement du langage naturel (NLP) :\n",
                "\n",
                "| Caractéristique | MLP | RNN |\n",
                "| :--- | :--- | :--- |\n",
                "| **Traitement de la Séquence** | Non séquentiel (chaque mot est indépendant). | Séquentiel (traite les mots dans l'ordre). |\n",
                "| **Mémoire/Contexte** | Aucune mémoire des entrées précédentes. | Possède une boucle récurrente qui lui donne une 'mémoire' du contexte passé. |\n",
                "| **Partage de Poids** | Les poids sont spécifiques à chaque entrée (position). | Les poids sont partagés à travers la séquence, permettant d'apprendre des motifs de séquence. |\n",
                "| **Applications Clés** | Classification de spam, classification de documents. | Traduction automatique, génération de texte, reconnaissance vocale, analyse de sentiments contextuelle.\n",
                "\n",
                "En résumé, le RNN excelle dans les tâches où le **contexte** et l'**ordre des mots** sont essentiels pour la compréhension, comme la détection de la négation (ex: 'ce n'est pas bon') ou la résolution d'ambiguïtés sémantiques, ce qu'un MLP ne peut pas faire efficacement."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
